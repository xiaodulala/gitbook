{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction welcome Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/":{"url":"golang/","title":"Golang","keywords":"","body":"Introduction Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/Golang编程规范和最佳实践.html":{"url":"golang/Golang编程规范和最佳实践.html","title":"Go语言编码规范和最佳实践","keywords":"","body":"概述 Go语言虽然简单易学，但是想要变成真正的编程个高手，写出易阅读，效率高，共享性和扩展性都比较优秀的高质量代码却是一件不简单的事情。 如何写出优雅且高质量的Go代码呢？ 遵循Go编码规范,这是最容易实现的途径。可以从Go社区中获取。比较受欢迎的是Uber Go 语言编码规范 学习并遵循前辈们探索沉淀下来的一些最佳实践。如 Effective Go：高效 Go 编程，由 Golang 官方编写，里面包含了编写 Go 代码的一些建议，也可以理解为最佳实践。 Go Code Review Comments：Golang 官方编写的 Go 最佳实践，作为 Effective Go 的补充。 本文是对这些规范和实践的一些总结。 编码规范 错误码规范 错误代码： 100101 10 服务 01 模块 01 模块下的错误码序号，每个模块可以注册 100 个错误 说明: 错误码用纯数字表示。每个部分分别代表服务 模块 错误码序号。每个模块可以注册100个错误。 Code 代码从 100101 开始。1000以下为保留code 通用错误设计如下： 服务 模块 说明 10 00 通用-基本错误 10 01 通用-数据库类错误 10 02 通用-认证授权类错误 10 03 通用-编码类错误 11 01 自己服务-用户模块错误 11 02 自己服务-xx模块错误 为什么这么设计: 如何设计一套合理的错误码 使用错误包: github.com/xiaodulala/component-tools/tree/main/pkg/errors 通用错误码引用：github.com/xiaodulala/component-tools/tree/main/component/errorcode 错误码注册工具和错误码文档生成工具: github.com/xiaodulala/component-tools/tree/main/tools/codegen 错误处理 error作为函数的返回值,必须对error进行处理。或将返回值赋值给明确忽略。对于defer xx.Close() 可以不用显示处理。 func load() error { // normal code } // bad load() // good _ = load() 如果一个函数返回了 value,error。你不能对这个value做任何假设，必须先判断error。唯一可以忽略error的是你连value都不关心。 error作为函数的值返回且有多个返回值的时候，error必须是最后一个参数。 尽早进行错误处理，并尽早返回，减少嵌套。 //bad if err!=nil{ //error code }else{ //normal code } //good if err!=nil{ return err } // normal code 错误描述建议 告诉用户他们可以做什么，而不是告诉他们不能做什么。 当声明一个需求时，用 must 而不是 should。例如，must be greater than 0、must match regex ‘[a-z]+’。 当声明一个格式不对时，用 must not。例如，must not contain。 当声明一个动作时用 may not。例如，may not be specified when otherField is empty、only name may be specified。 引用文字字符串值时，请在单引号中指示文字。例如，ust not contain ‘…’。 当引用另一个字段名称时，请在反引号中指定该名称。例如，must be greater than request。 指定不等时，请使用单词而不是符号。例如，must be less than 256、must be greater than or equal to 0 (不要用 larger than、bigger than、more than、higher than)。 指定数字范围时，请尽可能使用包含范围。 建议 Go 1.13 以上，error 生成方式为 fmt.Errorf(\"module xxx: %w\", err)。 错误描述用小写字母开头，结尾不要加标点符号，例如： // bad errors.New(\"Redis connection failed\") errors.New(\"redis connection failed.\") // good errors.New(\"redis connection failed\") 最佳实践 错误处理 错误只处理一次,打印日志也算一种错误处理。不要造成日志冗余。 func Bar()error{ _,err:=ioutil.ReadFile(\"./test.yaml\") if err!=nil{ log.Println(err) //bad return err } return nil } 在你的应用代码中,使用errors.new()或者errors.errorf返回错误 func parseArgs(args []string)error{ if len(args) 如果调用的是其他的函数，通常直接返回 err:=bar() if err!=nil{ return err } 如果调用的第三方库或者标准库的。考虑使用Warp或者Warpf保存堆栈信息。 func bar()error{ path:=\"./a.txt\" _,err:=os.Open(path) if err!=nil{ return errors.Wrapf(err,\"faild to open %q\",path) } return nil } 在程序的顶部或者是工作的 goroutine 顶部(请求入口)，使用 %+v 把堆栈详情记录。 func main() { err := app.Run() if err!=nil{ fmt.Printf(\"err:%+v\\n\",err) } } 使用error.Cause获取根错误再进行sentinel errror判断。或者直接使用Is函数。 选择 wrap error 是只有 applications 可以选择应用的策略。具有最高可重用性的包只能返回根错误值。此机制与 Go 标准库中使用的相同(kit 库的 sql.ErrNoRows)。 Packages that are reusable across many projects only return root error values. 如果你开发的是一个基础组件或者工具库。请返回确定的根错误值，不要返回包装错误。 一旦确定函数/方法将处理错误，错误就不再是错误。如果函数/方法仍然需要发出返回，则它不能返回错误值。它应该只返回零(比如降级处理中，你返回了降级数据，然后需要 return nil)。 Once an error is handled, it is not allowed to be passed up the call stack any longer. 参考引用 Rob Pike 所有关于 Go 的谚语 Uber Go 语言编码规范 孔令飞老师的极客时间的 Go语言项目实战 毛剑老师极客时间 Go进阶训练营 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/kernel/":{"url":"golang/kernel/","title":"Go语言核心","keywords":"","body":"Introduction Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/kernel/Go语言测试.html":{"url":"golang/kernel/Go语言测试.html","title":"Go语言如何测试","keywords":"","body":" 概述 在Go项目开发中,我们需要保证我们开发的模块功能稳定，且性能高效。所以我们要对我们自己的模块进行单元测试和性能测试。 在Go语言中，提供了Testing包来对我们的代码进行测试。 测试用例规范 测试用例文件必须以_test.go结尾。go test命令执行时会遍历当前包下所有的以_test.go文件作为测试用例源码文件。 测试用例函数必须以 Test、Benchmark、Example开头,后面直接跟函数名，函数名首字母需要大写。如：TestPrintHello。如果一个函数有多个测试用例,函数名称尽量表达出此函数的测试目的。 测试用例中变量命名规范: 测试用例中我们经常会定义输入和输出变量,最后比较输入和输出来判断测试用例是否通过。这两类变量通常定义为 expencted/actual或者是got/want。 单元测试 单元测试都是以Test开头。函数参数必须为 *test.T 如: func TestPrintHello(t *testing.T) { want := \"dy\" if got := PrintHello(\"dy\"); got != want { t.Errorf(\"want %s,bug got %s\", want, got) } } 这样的写法需要每次使用if比较输入和输出。我们可以使用github.com/stretchr/testify包来直接对比输入和输出。 func TestPrintHello(t *testing.T) { want := \"dy\" got := PrintHello(\"dy\") assert.Equal(t, want, got, \"values should be equal\") } 执行go test需要指定包路径,否则默认执行当前路径下的包的测试用例 # 以上测试用例执行 go test ./user go test -v参数,显示所有测试函数的运行细节。 go test -v ./user go test -run= 指定要指定的测试函数 go test -run=\"TestPrint.*\" go test -count=N 指定函数执行次数 go test -v -run=\"TestPrint.*\" -count=2 ./user 多输入测试用例 如果测试用例中要枚举多个输入进行测试。最好的方式是定义一个输出输出结构,遍历执行并对比结果: func TestPrintHelloMutil(t *testing.T) { tests := []struct { arg string want string }{ {arg: \"dy\", want: \"dy\"}, {arg: \"abc\", want: \"abc\"}, } for _, tt := range tests { got := PrintHello(tt.arg) assert.Equal(t, tt.want, got, \"values should be equal\") } } 自动生成单元测试代码 通过上面的示例我们大概了解,大部分的测试用例基本套路就是定义参数得到got。和之前的want做比较。这样就可以抽象出一个模型。 为了减少编写测试用例的时间,我们可以使用 gotests库来自动生成测试用例代码。这个库就是上面模型的实现。 安装工具 # go 生成测试用例代码 cd /users gotests -all -w . 补全代码 func TestNewUser(t *testing.T) { type args struct { name string age uint8 } tests := []struct { name string args args want *User wantErr bool }{ // TODO: Add test cases. {name: \"with all\", args: args{name: \"dy\", age: 20}, want: &User{Name: \"dy\", Age: 20}, wantErr: false}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { got, err := NewUser(tt.args.name, tt.args.age) if (err != nil) != tt.wantErr { t.Errorf(\"NewUser() error = %v, wantErr %v\", err, tt.wantErr) return } if !reflect.DeepEqual(got, tt.want) { t.Errorf(\"NewUser() = %v, want %v\", got, tt.want) } }) } } 补全: // TODO: Add test cases. 性能测试 函数名称必须以Benchmark开头 参数必须是 Testing.B # b.N 为循环次数。N会在运行时自动调整。知道性能测试可以持续运行足够的时间。 func BenchmarkMax(b *testing.B) { for i := 0; i 运行性能测试函数 go test -bench=\".*\" ` # 输出 goos: darwin goarch: amd64 pkg: fuck_demo/user cpu: Intel(R) Core(TM) i5-5287U CPU @ 2.90GHz BenchmarkMax-4 315559854 3.681 ns/op PASS ok fuck_demo/user 2.086s # BenchmarkMax-4 4个cpu线程参与了此次测试。 # 315559854 循环了多少次。 # 3.681 ns/op 每次操作耗时 3.681纳秒。 需要注意,如果在性能测试函数中有一些耗时的初始化操作，这个时间不能计算在性能测试之内。所以需要重置性能计数。 func BenchmarkMax(b *testing.B) { // 耗时操作 fmt.Println(\"do something\") time.Sleep(time.Second * 1) b.ResetTimer() for i := 0; i # 显示使用内存信息 go test -bench=\".*\" -benchmem BenchmarkMax-4 323694256 3.678 ns/op 0 B/op 0 allocs/op # 0 B/op 每次执行分配了多少内存 # 0 allocs/op 每次执行分配了多少**次**内存 都是越少越好。 # 指定参与的cpu个数 go test -bench=\".*\" -GOMAXPROCS=2 # 指定测试时间(N)和循环次数(Nx) go test -bench=\".*\" -benchtime=10s 执行10秒 go test -bench=\".*\" -benchtime=100x 执行100次 # 指定测试超时时间 go test -bench=\".*\" -timeout=20s 示例测试 如果你写的模块需要被其他人调用。你可以在代码中写示例测试，用来演示你模块的使用方式。 示例测试一般保存在example_test.go文件中。 函数必须以Example开头，没有输入参数，没有返回值。 示例测试通过输出注释来判断测试是否通过.输出注释格式为 Output: 结果值 或者Unordered output:开头的注释 func ExampleFunc() { fmt.Println(strings.HasPrefix(\"_abc\", \"_\")) fmt.Println(math.Abs(-100)) // Output: // true // 100 } 示例函数命名规则 func Example() { ... } // 代表了整个包的示例 func ExampleF() { ... } // 函数F的示例 func ExampleT() { ... } // 类型T的示例 func ExampleT_M() { ... } // 方法T_M的示例 # 当一个函数 类型 或者方法有多个示例测试时 func ExampleReverse() func ExampleReverse_second() func ExampleReverse_third() 大型示例测试 通常在一个文件中。只用一个Example函数。 TestMain函数 主要用来做测试之前的准备工作和测试之后的清理工作。如连接数据库,清理临时文件等。 函数名必须是TestMain 参数必须是 *testing.M func TestMain(m *testing.M) { fmt.Println(\"do some stepup\") m.Run() fmt.Println(\"do some cleanup\") } Mock测试 在单元测试中,我们经常会碰到如下情况： 函数内部调用了数据库操作等外部依赖。 函数内部包含了一些未实现的调用。 此时,我们可以通过mock来处理。gomock是go官方提供的mock解决方案。 主要分为两部分: gomock库和mockgen gomock包用来完成对象生命周期的管理。 mockgen工具用来生成interface对应的mock类源文件。 安装 # gomock包下载 go get github.com/golang/mock/gomock # mockgen工具下载 go install github.com/golang/mock/mockgen@latest 示例 假设我们现在user中有一个函数是获取用户的微信UUID，但是此方法还没有实现。所以我们没有办法实现这个函数的测试用例。在这种情况下，我们就需要使用mock测试了。 # user.go func GetWechatUUID(wechater wechat.Wechater, name string) string { uuid := wechater.GetUUID(name) return uuid } # interface package wechat type Wechater interface { GetUUID(name string) string } 首先，使用mockgen工具,生成要mock的接口的实现。 mockgen -destination wechat/mock/mock_wechat.go -package mock_wechat fuck_demo/wechat Wechater # -destination: 存放mock类代码的文件。如果你没有设置这个选项，代码将被打印到标准输出 # -package: 用于指定mock类源文件的包名。如果你没有设置这个选项，则包名由mock_和输入文件的包名级联而成 # fuck_demo/wechat 是你接口所在的包 # Wechater 接口名称。可以是多个。用,分隔 使用mock文件,完成单元测试。 可以看到在指定路径下生成了mock_wechat.go文件。其中定义了一些函数和方法。这些方法用来支持我们编写单元测试。 // GetUUID indicates an expected call of GetUUID. func (mr *MockWechaterMockRecorder) GetUUID(arg0 interface{}) *gomock.Call { mr.mock.ctrl.T.Helper() return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"GetUUID\", reflect.TypeOf((*MockWechater)(nil).GetUUID), arg0) } # 单元测试中使用 func TestGetUUID(t *testing.T) { ctrl := gomock.NewController(t) defer ctrl.Finish() mockWechater := mock_wechat.NewMockWechater(ctrl) mockWechater.EXPECT().GetUUID(\"dy\").Return(\"dy\") got := GetWechatUUID(mockWechater, \"dy\") if got != \"dy\" { t.Errorf(\"get uuid fail\") } } 通过mock,不用我们自己去实现一个接口。降低了用例编写的复杂度。 mockgen的使用 源码模式 如果有接口文件,则通过源码模式来生成mock代码: mockgen -destination wechat/mock/mock_wechat.go -source wechat/wechat-interface.go # -source 要模拟的接口文件 反射模式 mockgen -destination wechat/mock/mock_wechat.go -package mock_wechat fuck_demo/wechat Wechater # 我们上面的示例用的是这种方式。 注释模式 如果要模拟的接口文件有多个，且分布在不同的文件中。我们需要对每个文件执行多次mockgen命令。mockgen 提供了一种通过注释生成mock文件的方式,需要借助go generate工具 在接口文件代码中,添加以下注释: //go:generate mockgen -destination mock/mock_wechat.go -package wechat fuck_demo/wechat Wechater type Wechater interface { GetUUID(name string) string } # 在命令行中执行 go generate ./... 使用mock代码编写单元测试 # 单元测试中使用 func TestGetUUID(t *testing.T) { ctrl := gomock.NewController(t) defer ctrl.Finish() mockWechater := mock_wechat.NewMockWechater(ctrl) mockWechater.EXPECT().GetUUID(\"dy\").Return(\"dy\") got := GetWechatUUID(mockWechater, \"dy\") if got != \"dy\" { t.Errorf(\"get uuid fail\") } } 创建mock控制器 defer 操作完之后回收。 使用控制器返回一个mock对象。 mock对象调用 gomock 支持以下参数匹配： gomock.Any()，可以用来表示任意的入参。 gomock.Eq(value)，用来表示与 value 等价的值。 gomock.Not(value)，用来表示非 value 以外的值。 gomock.Nil()，用来表示 None 值。 EXPECT()得到 Mock 的实例，然后调用 Mock 实例的方法，该方法返回第一个Call对象，然后可以对其进行条件约束，比如使用 Mock 实例的 Return 方法约束其返回值。Call对象还提供了以下方法来约束 Mock 实例： func (c *Call) After(preReq *Call) *Call // After声明调用在preReq完成后执行 func (c *Call) AnyTimes() *Call // 允许调用次数为 0 次或更多次 func (c *Call) Do(f interface{}) *Call // 声明在匹配时要运行的操作 func (c *Call) MaxTimes(n int) *Call // 设置最大的调用次数为 n 次 func (c *Call) MinTimes(n int) *Call // 设置最小的调用次数为 n 次 func (c *Call) Return(rets ...interface{}) *Call // // 声明模拟函数调用返回的值 func (c *Call) SetArg(n int, value interface{}) *Call // 声明使用指针设置第 n 个参数的值 func (c *Call) Times(n int) *Call // 设置调用次数为 n 次 fake测试 根据接口伪造一个实现接口的实例。 测试覆盖率 生成测试覆盖率数据 # 当前目录下所有文件全部提取,查看是否有对应的测试用例。生成测试覆盖率数据 go test -coverprofile=coverage.out ./... 分析覆盖率文件 go tool cover -func=coverage.out # 输出 fuck_demo/user/user.go:13: NewUser 100.0% fuck_demo/user/user.go:20: GetName 0.0% fuck_demo/user/user.go:24: SetAge 0.0% fuck_demo/user/user.go:29: PrintHello 0.0% fuck_demo/user/user.go:33: Max 0.0% fuck_demo/user/user.go:37: GetWechatUUID 100.0% total: (statements) 37.5% 生成html文件在浏览器查看 go tool cover -html=coverage.out -o coverage.html [!NOTE] 有时候代码测试覆盖率会作为准许合入分支的一项检查。如果覆盖率不足，会导致合入分支失败。我们可以使用go-junit-report 将覆盖率结构文件转换为xml,供其他CI系统使用。 [!WARNING] 使用mock生成的代码是不需要测试用例的，我们需要将生成的覆盖率文件中mock_*.go的文件去掉，否则会影响整体的测试覆盖率计算。 其他mock sqlmock 模拟数据库连接 httpmock 模拟http请求 bouk/monkey 猴子补丁,替换函数指针来修改任意函数的实现。mock最终解决方案。 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/kernel/Go语言错误处理.html":{"url":"golang/kernel/Go语言错误处理.html","title":"Go语言错误处理","keywords":"","body":"Go中的error 在底层的实现中，error类型是一个普通的接口。 // The error built-in interface type is the conventional interface for // representing an error condition, with the nil value representing no error. type error interface { Error() string } 所以，实现我们自己的错误类型非常容易。只要我们实现Error() string方法，这个方法的结构体都会被视为一个合法的错误值并可以被返回 type MyError struct { code int msg string } func (e *MyError)Error()string{ return fmt.Sprintf(\"code:%d,msg:%s\", e.code, e.msg) } func main() { err:= func1() fmt.Println(err) } func func1()error{ return &MyError{code: 1,msg: \"resource not found\"} } 内置的错误字符串(errorString)结构体 我们经常会使用errors.New(\"test err\")或者fmt.Errorf()来生成一个错误值。这个错误值的结构其实就是errorString。errorString实现了error接口的方法,所以可以当做一个合法的错误值。它做的事情就是保存一个string,并且由error接口返回。 package errors // New returns an error that formats as the given text. // Each call to New returns a distinct error value even if the text is identical. func New(text string) error { return &errorString{text} } // errorString is a trivial implementation of error. type errorString struct { s string } func (e *errorString) Error() string { return e.s } errors不是异常(exceptions) 在其他语言中,exceptions机制各不相同。 c++中，你无法确定被调用者会抛出什么异常。而在java中，引入了checkd exception,方法的所有者必须申明可能会抛出哪些exception,而调用者必须处理。这样的话，java中的异常不再是异常，他们从良性到灾难性的都有，需要由调用者来判断。 go中明确了异常和错误的概念。异常就是程序出现不可预期的致命问题,无法再继续运行，引入panic机制。错误是可以预料的错误，是业务处理的中的一部分。这里使用的是error。 对于真正意外的情况，那些表示不可恢复的程序错误，例如索引越界、不可恢复的环境问题、栈溢出，我们才使用 panic。对于其他的错误情况，我们应该是期望使用 error 来进行判定。 定义 错误的方式 sintinel error 预定义的特定错误，叫做 sintinel error。 这是我们经常使用的定义错误的方式。如标准库中的io.EOF。 使用预定义判断是最不灵活的错误处理策略。因为调用方必须使用 \"\\==\" 来比较预定义错误的值。当你想要提供更多的上下文时，就出现了一个问题，新增了上下文的错误会影响\"==\"检查 func main() { err:=bar() // 影响==判断 if err == simple.ErrorA{ fmt.Println(\"handler errorA\") } fmt.Println(err) } func bar()error{ err:=simple.SimpleA() if err!=nil{ // 增加了上下文信息 return fmt.Errorf(\"bar:%w\",err) } return nil } 不应该依赖检测error.Error()的输出。Error方法只是用来方便程序员输出字符串用来记录日志。而不应该被程序依赖(测试用例可能会用)。 预定义特定错误模式在两个包之间创建了源代码的依赖关系。例如检查错误是否等于io.EOF。你的代码必须导入io包。如果有很多包都需要导出各自的错误值。可能存在耦合。 所以我们应该尽量避免使用预定义特定错误的方式。 error types 实现 error interface接口的自定义错误类型。使用这种方式我们可以为错误信息增加更丰富的上下文信息。如标准库: type PathError struct { Op string Path string Err error } func (e *PathError) Error() string { return e.Op + \" \" + e.Path + \": \" + e.Err.Error() } 但是在使用时,我们必须进行断言来判断是否是此错误: func main() { err:=pathErr() if err!=nil{ if _,ok:=err.(*fs.PathError);ok{ fmt.Println(\"handle path error\") } } // normal } func pathErr()error{ return &fs.PathError{ Op: \"create\", Path: \"/home/test\", Err: errors.New(\"filepath not found\"), } } 这种方式比sentinel方式好一些，因为它能可以捕获更多的上下文信息。但sentinel存在的一些问题依然没有得到解决。 为自定义错误增加特定的行为 net标准库 // An Error represents a network error. type Error interface { //扩展error接口。增加行为 error Timeout() bool // Is the error a timeout? Temporary() bool // Is the error temporary? } type UnknownNetworkError string func (e UnknownNetworkError) Error() string { return \"unknown network \" + string(e) } func (e UnknownNetworkError) Timeout() bool { return false } func (e UnknownNetworkError) Temporary() bool { return false } 在这种情况下,我们可以直接判断错误的行为。而不是去判断错误的类型或者值。我们也无需再再关注底层的err类型。 常见的error处理和存在的问题 在error中最常见的处理方式就是通过多值进行返回，明了的暴露出来，要么处理，要么略过。最常见的处理方式如下： func bar()error{ err:= foo() if err!=nil{ return fmt.Errorf(\"bar:%s\",err) } return nil } func foo()error{ err:= simple.SimpleA() if err!=nil{ return fmt.Errorf(\"foo:%s\",err) } return nil } 尽管我们通过fmt.Errorf的方式为错误增加了一些上下文信息，但还是不利于我们去排查错误。我们需要知道更多的错误信息: 在什么文件，在哪一行用来更好的定位。 错误处理最佳实践(github.com/pkg/errors) github.com/pkg/errors为我们封装了更加丰富的错误处理方式：保存错误堆栈信息、错误包装、格式化输出等功能。 几个重要结构和函数 fundamental 基本错误包含错误消息和堆栈信息，但是没有调用者。 // fundamental is an error that has a message and a stack, but no caller. type fundamental struct { msg string *stack } func main() { err1:=errors.New(\"new error\") err2:=errors.Errorf(\"new errorf\") fmt.Printf(\"%+v\\n\\n\",err1) //可以格式化输出 fmt.Printf(\"%+v\\n\\n\",err2) } withMessage 包装错误信息，但是不包含堆栈信息。 通过 WithMessage(err error, message string) error 和 WithMessagef(err error, format string, args ...interface{}) error函数来包装好的错误信息。 type withMessage struct { cause error msg string } func (w *withMessage) Error() string { return w.msg + \": \" + w.cause.Error() } func (w *withMessage) Cause() error { return w.cause } // Unwrap provides compatibility for Go 1.13 error chains. func (w *withMessage) Unwrap() error { return w.cause } func (w *withMessage) Format(s fmt.State, verb rune) { switch verb { case 'v': if s.Flag('+') { fmt.Fprintf(s, \"%+v\\n\", w.Cause()) io.WriteString(s, w.msg) return } fallthrough case 's', 'q': io.WriteString(s, w.Error()) } } func main() { err := foo() fmt.Printf(\"main err:%s\\n\\n\",err) fmt.Printf(\"main err:%v\\n\\n\",err) fmt.Printf(\"main err:%+v\\n\\n\",err) } func foo()error{ _,err:=ioutil.ReadFile(\"./test.yaml\") return errors.WithMessage(err,\"read file err\") } withStack 含有堆栈信息的错误包装。使用Wrap(err error, message string) error或者Wrapf(err error, format string, args ...interface{}) error type withStack struct { error // 这里的error其实是withMessage 堆栈信息是对withMessage的进一步封装 *stack } func (w *withStack) Cause() error { return w.error } // Unwrap provides compatibility for Go 1.13 error chains. func (w *withStack) Unwrap() error { return w.error } func (w *withStack) Format(s fmt.State, verb rune) { switch verb { case 'v': if s.Flag('+') { fmt.Fprintf(s, \"%+v\", w.Cause()) w.stack.Format(s, verb) return } fallthrough case 's': io.WriteString(s, w.Error()) case 'q': fmt.Fprintf(s, \"%q\", w.Error()) } } 获取错误根本原因 func foo()error{ _,err:=ioutil.ReadFile(\"./test.yaml\") return errors.Wrap(err,\"read file err\") } fmt.Println(\"main:\",errors.Cause(err)) // open ./test.yaml: no such file or directory 错误判断和解析 Is As Unwarp 从go 1.13以后,标准库采用了此包的错误处理方式。并添加了 Is As Unwap几个函数来更方便的处理错误。 此包为了兼容1.13,同时也增加了三个函数，内部都是调用的标准库函数。 func Is(err, target error) bool { return stderrors.Is(err, target) } func As(err error, target interface{}) bool { return stderrors.As(err, target) } func Unwrap(err error) error { return stderrors.Unwrap(err) } 由于错误采用包装的方式增加上下文信息并向上层传递。上层如果想要判断错误是否为某个具体错误,就不能直接用比较值的方式。Is方法用来将包装好的error剥开，并判断是否包装了目标错误。 func main() { err :=bar() if err!=nil{ if errors.Is(err,errFileNotFound){ fmt.Printf(\"%+v\\n\",err) } } } func bar()error{ return errors.WithMessage(foo(),\"bar\") } func foo()error{ return errFileNotFound } warp error的最佳实践 错误包装虽然可以方便我们处理错误,但也不能随意的进行包装，造成错误信息太过繁琐。这里对于错误的包装也有一些注意的地方 错误只处理一次,打印日志也算一种错误处理。不要造成日志冗余。 func Bar()error{ _,err:=ioutil.ReadFile(\"./test.yaml\") if err!=nil{ log.Println(err) //bad return err } return nil } 在你的应用代码中,使用errors.new()或者errors.errorf返回错误 func parseArgs(args []string)error{ if len(args) 如果调用的是其他的函数，通常直接返回 err:=bar() if err!=nil{ return err } 如果调用的第三方库或者标准库的。考虑使用Warp或者Warpf保存堆栈信息。 func bar()error{ path:=\"./a.txt\" _,err:=os.Open(path) if err!=nil{ return errors.Wrapf(err,\"faild to open %q\",path) } return nil } 在程序的顶部或者是工作的 goroutine 顶部(请求入口)，使用 %+v 把堆栈详情记录。 func main() { err := app.Run() if err!=nil{ fmt.Printf(\"err:%+v\\n\",err) } } 使用error.Cause获取根错误再进行sentinel errror判断。或者直接使用Is函数。 选择 wrap error 是只有 applications 可以选择应用的策略。具有最高可重用性的包只能返回根错误值。此机制与 Go 标准库中使用的相同(kit 库的 sql.ErrNoRows)。 Packages that are reusable across many projects only return root error values. 如果你开发的是一个基础组件或者工具库。请返回确定的根错误值，不要返回包装错误。 一旦确定函数/方法将处理错误，错误就不再是错误。如果函数/方法仍然需要发出返回，则它不能返回错误值。它应该只返回零(比如降级处理中，你返回了降级数据，然后需要 return nil)。 Once an error is handled, it is not allowed to be passed up the call stack any longer. go2错误处理 https://go.googlesource.com/proposal/+/master/design/29934-error-values.md Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/kernel/Golang协程调度机制.html":{"url":"golang/kernel/Golang协程调度机制.html","title":"Go协程调度机制","keywords":"","body":"参考 极客时间-孟凡杰-云原生训练营 前置知识 Golang作为一门新的语言，使用了用户态线程-协程这个概念。为什么会有协程这个概念，他和线程以及进程有什么却别？好处有哪些呢？ 首先我们需要对一些基本知识有一定的了解，以此为基础来更深刻的了解为什么Golang要写一个Goroutine出来。 进程和线程 进程: 资源分配的基本基本单位。 线程: 调度的基本单位 无论是进程还是线程,在linux中都以task_struct描述。从内核角度看,进程与线程没有本质的区别。线程就是没有自己独立资源的进程。 在linux中，进程的创建一般使用fork，fork出来的进程与原始的进程只有父子关系。而没有其他的联系。fork出来的进程有自己单独的内存空间，文件系统，文件操作符已经信号 线程的创建一般使用pthread_cretae, 线程的创建不会重新分配资源，而是与原来的process共享其资源。 进程内存 在现代的计算机中,操作系统都是支持多进程的。如果直接让多个进程直接访问物理内存,内存的分配会出现问题。由此引出了虚拟内存。 虚拟内存和物理内存的关系是通过页表维护的。为了避免页表数据量太大，linux使用了多级页表来减少页表对于内存的开销。 每启动一个进程，操作系统就为进程生成一个虚拟内存来对应到物理内存。在linux中内核中进程的虚拟内存划分如图。 我们可以使用size命令直接查看应用程序虚拟内存中每个段所占用的大小。 package main const name = \"aaa\" func main(){ } # 编译以上程序 go build main.go size main __TEXT __DATA __OBJC others dec hex 753664 224672 0 16829856 17808192 10fbb40 # 获取操作系统页表大小 getconf PAGE_SIZE 4096 CPU 对于内存的访问 CPU上有个Memory Management Uint(MMU)单元 CPU 把虚拟地址给MMU,MMU去物理内存中查询页表，得到实际的物理地址。 CPU维护一份缓存 Translation Lookaside Buffer(TLB),缓存虚拟地址和无物理地址的映射关系。 进程切换的开销 综上，我们可以知道，如果切换进程需要有以下开销: 直接开销 切换页表全局目录(PGD)。因为每个进程都有自己独立的进程虚拟地址空间。进程的切换代表着整个虚拟地址空间的切换。 切换内核态堆栈 切换上下文(保存进程执行) 刷新TLB 系统调度器的代码执行。 间接开销 CPU缓存生效导致进程需要到内存直接访问的IO操作变多。 线程切换开销 线程本质上只是一批共享资源的进程，线程切换本质上依然需要内核进行进程切换。 由于线程共享内存资源，因此一个进程的所有线程共享虚拟地址空间，线程切换相比于进程切换，主要节省了虚拟地址空间的切换 用户线程(协程) 通过一些前置知识，我们知道。就算是多个线程之间的切换，也只是节省了 虚拟地址空间的切换的开销。切换过程中依然需要内核进行操作。 有没有一种方法，可以在无需内核帮助下，应用程序在用户空间创建可执行的单元，创建销毁完全在用户态完成。 这就是用户态线程，也叫轻量级线程，也就是协程。 假设一个cpu上同时有多个内核级线程，这几个线程通过非抢占式调度策略来均匀的使用cpu的划分的时间片。如果我们可以在用户态创建多个用户态的线程，并绑定到一个内核线程。当在这个内核线程有效的时间片内，某一个用户态线程发生了阻塞，我们可以在切换到另一个用户态线程，此时的切换完全发生在用户空间，节省了内核部分的很大开销。 基于用户态线程这种切换可以节省很大的开销，无需操作系统进行系统调用完成系统级的线程切换。 Golang语言就是基于此种机制设计并实现了自己的协程-goroutine。 Goroutine 介绍 Go语言基于PMG模型实现了用户态线程。 G: 表示goroutine,每个goroutine都有自己的栈空间，定时器。初始化的栈空间在2k左右，空间随着需求增长。 M: 抽象化代表内核线程,记录内核线程栈信息，当goroutine调度到线程时,使用该goroutine自己的展信息。 P: 代表调度器,负责调度goroutine,维护一个本地的goroutine队列，m从p上获得goroutine并执行，同时还负责部分内存的管理。 PMG模型细节 内核线程和M的对应关系： 程序启动时首先会根据系统CPU的数量启动M 然后golang会维护一个P列表，当系统中没有任何goroutine时,这些P上是没有任何任务的。最常见的P是运行状态，此时P是被分配的M上的。如果P中的goroutine有系统调用并且被M获取到这个groutine，此时这个M陷入到系统调用中。P会和他解绑并寻找其他空闲的M。 全局的goutine free是一个线程池的概念，我不需要没都新建gouritne实例。当新建gouritne先看全局的free队列有没有，有的话直接使用。使用完了再放回。 每个P会维护一个本地的goroutine队列。同时还有一个全局可运行的groutine队列。新建的goutine会首先尝试放入当前的P本地队列中，数量超过256个后放入全局队列中。 P队列中的goroutine是不平衡的。如果当前P中没有可执行的goroutine,则先到全局可运行队列中找。如果也没有，从其他的P中找，直接取一半。叫做工作窃取。 如果groutine有阻塞，则放入阻塞队列。 如果一个P被调度到了M上，除非要系统调动等情况发生，P是不会主动与M解除关系的。这样就大大的减少了线程的切换。 P的状态 Pidle: 处理器没有运行用户代码或者调度器。被空闲队列或者改变其状态的结构持有，运行队列为空。 Prunning: 被线程M持有,并且正在执行用户代码或者调度器。 PSyscall: 没有执行用户代码，当前线程陷入系统调用。 Pgcstop: 被线程M持有，当前处理器由于垃圾回收被停止。 Pdead: 当前吹起已经不被使用。 G的状态 Gidle: 刚刚被分配并且还没有被初始化，值为0，为创建goroutine后的默认值。 Grunabele: 没有执行代码，没有栈的所有权，存储在运行队列中，可能在某个P的本地队列或者全局队列中。 Grunning: 正在执行代码的goroutine,拥有栈的所有权。 Gsyscall: 正在执行系统调用，拥有栈的所有权，与P脱离，但是与某个M绑定，会在调用结束后被分配到运行队列。 Gwating: 被阻塞的goroutine,阻塞在某个channel的发送或者接收队列。 Gdead: 当前goroutine未被使用，没有执行代码，可能有分配的栈，分布在空闲列表gFree，可能是一个刚刚初始化goroutine，也可能是执行了goexit退出的goroutine. Gcopystac: 栈正在被拷贝，没有执行代码，不在运行队列上，执行权在。 Gscan: GC正在扫描栈空间，没有执行代码，可以与其他状态同时存在。 G所处的位置 进程都有一个全局的G队列。 每个P拥有自己的本地执行队列。 在上面两个队列中的G都是可运行的。如果不在上诉两个队列中，则可能在以下位置： 处于channel阻塞状态的G被放在sudog 脱离了P绑定在M上的G,系统调用。 为了复用，执行结束进入P的gFree队列。G创建过程 获取或者创建新的Groutine结构体 从处理器的gFree列表中查询空闲的Goroutine。 如果不存在空闲的goroutine，会通过runtime.malg创建一个栈大小足够的新结构体。 将函数传入的参数移到goroutine的栈上。 更新goroutine调度相关的属性，更新状态为Grunnable 返回的goroutine会存储在全局变量allgs中。 调度器的行为 为了保证公平，当全局队列中有待执行的g时，通过调度算法保证有一定的几率(1/61)会从全局的奴性队列中查找对应的g。 从处理器本地的运行队列中渣朝待执行的g 如果前两种方法都没有找到g，会通过runtime.findrunnable进行阻塞的查找g。 从本地队列，全局队列中找。 从网络轮询器中查找是否有g等待运行。 通过runtime.runqsteal尝试从其他随机的处理器中窃取一半待运行的g。 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/kernel/内存管理.html":{"url":"golang/kernel/内存管理.html","title":"Go内存管理","keywords":"","body":"前言 我们Golang进程调度我们知道内存可以分为数据段，代码段和堆栈等。对于java或者golang等高级的语言来说，他们的内存管理主要是针对堆的内存管理。 堆内存的管理机制 初始化连续的内存块作为堆内存 有内存申请的时候，Allocator从堆内存的未分配区域分割小内存块。 用链表将已经分配的内存连接起来。 需要信息描述每个内存块的元数据: 大小，是否使用，下一个内存块的地址等。 内存回收就是扫描堆内存，将不再被使用的内存设置为unused. 堆内存管理的挑战: 内存分配需要系统调用，在频繁内存分配的时候,系统性能较低。 多线程共享相同的内存空间，同时申请内存时，需要加锁，否则会产生同一块内存被多个线程访问的情况。 内存碎片化问题，经过不断的内存分配和回收，内存碎片会比较严重，内存的使用效率降低。 TCMalloc page： 内存页，一块8k大小的内存空间。Go与操作系统之间的内存申请和释放，都是以page为单位的。 span： 内存块，一个或多个连续的page组成一个span sizeclass: 空间规格，每个span都带有一个sizeclass,标记着span中的page该如何使用 object:对象，用来存储一个变量数据内存空间，一个span在初始化时，会被切割成一堆等大 的 object ;假设 object 的大小是 16B ，span 大小是 8K ，那么就会把 span 中的 page 就会 被初始化 8K / 16B = 512 个 object 。所谓内存分配，就是分配一个 object 出去 对象大小定义 小对象大小:0~256KB 中对象大小:256KB~1MB 大对象大小:>1MB 小对象的分配流程 ThreadCache -> CentralCache -> HeapPage，大部分时候，ThreadCache 缓存都是足够的，不需要去访问 CentralCache 和 HeapPage，无系统调用配合无锁分配，分配效率是非常高的 中对象分配流程 直接在 PageHeap 中选择适当的大小即可，128 Page 的 Span 所保存的最大内存就是 1MB 大对象分配流程 从 large span set 选择合适数量的页面组成 span，用来存储数据 Go语言内存分配 内存回收 回收方式 引用计数(Python,PHP,Swift) 每一个对象维护一个引用计数,当引用该对象的对象被销毁的时候，引用计数减1，当引用计数为0的时候，回收该对象。 优点： 对象可以很快的被回收，不会出现内存耗尽或达到某个阈值时才回收 确定： 不能很好的处理循环引用，而且实时维护引用计数，有一定的代价。 标记-清除(golang) 从根变量开始遍历所有引用的对象，引用的对象被标记为“被引用”，没有被标记的进行回收 优点： 解决引用计数的缺点 缺点： 需要STW. 分代收集 按照生命周期进行划分不同的代空间，生命周期长的放入老年代，短的放入新生代，新生代的回收频率高于老年代的频率。 mspan结构： span由多个page组成。每个span按照sizeclass切分成多个块。 下面的位图就代表这些内存块的分配情况。 allocBits 记录了每块内存分配的情况 gcmarkBits 记录了每块内存的引用情况，标记阶段对每块内存进行标记，有对象引用的内存标记为1，没有标记为0 这两个位图的数据结构完全是一致的，标记接收则进行内存回收，会后的时候，将alloBits指向gcmarkBits，标记过的则存在，未进行标记的则进行回收。 GC工作流程 Golang GC的大部分处理是和用户代码并行的。 Mark: Mark Prepare: 初始化gc任务，包括开启写屏障和辅助GC,统计root对象的任务数量等。这个过程需要STW. GCDrains:扫描所有root对象，包括全局指针和goroutine(G)栈上的指针(扫描对应G栈时需停止该G)，将其 加入标记队列(灰色队列)，并循环处理灰色队列的对象，直到灰色队列为空。该过程后台并行执行 MarkTermination:完成标记工作，重新扫描(re-scan)全局指针和栈。因为Mark和用户程序是并行的，所以在Mark过 程中可能会有新的对象分配和指针赋值，这个时候就需要通过写屏障(write barrier)记录下来，re-scan 再检查一下，这 个过程也是会 STW 的 Sweep:按照标记结果回收所有的白色对象，该过程后台并行执行 SweepTermination:对未清扫的span进行清扫,只有上一轮的GC的清扫工作完成才可以开始新一轮的GC GC工作流程 三色标记 GC开始时，认为所有object都是白色，即垃圾 从root区开始遍历，被触达的object直为灰色。 遍历所有灰色，将他们内部的引用变量置为灰色，自身为黑色。 循环第三步，直到没有灰色的object，只剩下黑白两种，白色的是垃圾，黑色的为活跃对象。 对于黑色的object，如果在标记期间发生了写操作，写屏障会在真正赋值前将新对象标记为灰色。 比较过程中，mallocgc 新分配的object，会先被标记成黑色，再返回。 垃圾回收触发机制 内存分配量达到阈值触发GC 每次内存分配时都会检查当前内存分配量是否达到阈值。阈值=上次gc内存分配量*内存增长率。 内存增长率由变量GOGC控制。默认为100.即每当内存扩大一倍时，启动GC. 定期触发GC 默认情况下 最长2分钟触发一次。这个间隔在 src/runtime/proc.go:forcegcperiod 变量中被声明 手动触发 程序代码中也可以使用 runtime.GC()来手动触发 GC。这主要用于 GC 性能测试和统计。 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/lib/":{"url":"golang/lib/","title":"Go语言三方库","keywords":"","body":"Introduction Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/lib/aa.html":{"url":"golang/lib/aa.html","title":"Test包","keywords":"","body":"aa aaaa bb aaaa [!NOTE] note...... aaaaaa [!TIP] tip....... aaaaa [!WARNING] warning..... aaaaaa [!DANGER] danger...... ccc aaaaa dddd ddddd bbbbbbbb Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/lib/命令行参数解析工具Pflag.html":{"url":"golang/lib/命令行参数解析工具Pflag.html","title":"命令行参数解析工具-pflag包","keywords":"","body":"概述 pflag是一个更加高级的命令行参数解析工具。pflag是一个完全兼容goflag的包。但其功能更加强大。按照POSIX/ gnu风格的 --flags实现。 在Go项目中，我们经常会在实现各种服务或者命令行工具时使用命令行参数解析来控制应用行为。Pflag包可以为我们提供更加方便的命令行参数解析。 Kubernetes、Helm、Docker、Etcd等项目使用的也是Pflag包来解析命令行参数的。 Pflag包安装 go get github.com/spf13/pflag Pflag包的使用 导入包 import flag \"github.com/spf13/pflag\" pflag.type()方式: 使用长选项的方式将标志解析到指针变量中。 可设置默认值和帮助信息. func main() { var ip *int = pflag.Int(\"flagname\", 123, \"help message for flagname\") pflag.Parse() fmt.Printf(\"%d\\n\", *ip) } ☁ pflagDemo ./main 123 ☁ pflagDemo ./main --flagname 234 234 ☁ pflagDemo ./main -h Usage of ./main: --flagname int help message for flagname (default 123) pflag: help requested pflag.typeVar()方式: 先声名接收变量，使用长选项的方式将falg的值绑定到指定的变量中。 var flagvar int var flagbool bool func main() { pflag.IntVar(&flagvar, \"flagname\", 1234, \"help message\") pflag.BoolVar(&flagbool, \"flagbool\", true, \"flagbool help message\") pflag.Parse() fmt.Printf(\"%v,%v\\n\", flagvar, flagbool) } ☁ pflagDemo ./main 1234,true ☁ pflagDemo ./main --flagbool=false --flagname 2345 2345,false pflag.typeP() 或者 pflag.typeVarP(). 在以上两种方式的基础上,增加命令行段选项支持。 func main() { var ip = pflag.IntP(\"flagname\", \"f\", 1234, \"help message\") var flagBool bool pflag.BoolVarP(&flagBool, \"boolname\", \"b\", true, \"help message\") pflag.Parse() fmt.Printf(\"%d,%v\\n\", *ip, flagBool) } ./main -b=false -f 3333 指定了选项，但是没有指定选项值的默认值 func main() { var ip = pflag.IntP(\"flagname\", \"f\", 1234, \"help message\") pflag.Lookup(\"flagname\").NoOptDefVal = \"4321\" pflag.Parse() fmt.Println(*ip) // ./main 输出 1234 使用默认值 // ./main -f 输出 4321 执行了选项,没有指定值。使用NoOptDefVal的值 // ./main -f=3333 输出 3333 } 命令行语法 --flag // boolean flags, or flags with no option default values --flag x // only on flags without a default value --flag=x # example1: bool类型的flag, 或者设置了 noOptDefVal的flag -f // ok true或者是noOptDefVal的值 -f=true -f=3333 // ok -f true // invalid -f 3333 // invalid //example2: 非bool类型的flag, 或者没有设置noOptDefVal的值 -n 1234 -n=1234 -n1234 都ok flag的\"规范化\" 允许自定义函数.让你的标志名称在代码中使用时更加规范化，且方便用于比较。在命令行中的输入与代码中的标志等价。 例子: func main() { fset := pflag.NewFlagSet(\"test\", pflag.ExitOnError) fset.SetNormalizeFunc(wordSepNormalizeFunc) } // You want -, _, and . in flags to compare the same. aka --my-flag == --my_flag == --my.flag func wordSepNormalizeFunc(f *pflag.FlagSet, name string) pflag.NormalizedName { from := []string{\"-\", \"_\"} to := \".\" for _, sep := range from { name = strings.Replace(name, sep, to, -1) } return pflag.NormalizedName(name) } // You want to alias two flags. aka --old-flag-name == --new-flag-name func aliasNormalizeFunc(f *pflag.FlagSet, name string) pflag.NormalizedName { switch name { case \"old-flag-name\": name = \"new-flag-name\" } return pflag.NormalizedName(name) } 弃用标志或者标志的简写 func main() { v := pflag.String(\"badflag\", \"hello\", \"help message\") v1 := pflag.IntP(\"flagname\", \"f\", 123, \"help message\") pflag.CommandLine.MarkDeprecated(\"badflag\", \"please use --good-flag instead\") pflag.CommandLine.MarkShorthandDeprecated(\"flagname\", \"please --flagname only\") pflag.Parse() println(*v, *v1) } # 不显示 badflag ./main -h Usage of ./main: --flagname int help message (default 123) # 可以用 badflag 但会出现提示 ./main --badflag world Flag --badflag has been deprecated, please use --good-flag instead # 使用flagname的短选项会有提示 ./main -f 100 Flag shorthand -f has been deprecated, please --flagname only 影藏标志 func main() { var adminAct string pflag.StringVar(&adminAct, \"admin\", \"admin\", \"help message\") pflag.CommandLine.MarkHidden(\"admin\") pflag.Parse() } 使用 help 无法看到admin 标识 pflag包数据结构 每个一个命令行参数都会被解析成一个pflag.Flag类型的变量 type Flag struct { Name string // flag长选项的名称 Shorthand string // flag短选项的名称，一个缩写的字符 Usage string // flag的使用文本 Value Value // flag的值 DefValue string // flag的默认值 Changed bool // 记录flag的值是否有被设置过 NoOptDefVal string // 当flag出现在命令行，但是没有指定选项值时的默认值 Deprecated string // 记录该flag是否被放弃 Hidden bool // 如果值为true，则从help/usage输出信息中隐藏该flag ShorthandDeprecated string // 如果flag的短选项被废弃，当使用flag的短选项时打印该信息 Annotations map[string][]string // 给flag设置注解 } Flag的值是一个Value类型的接口，Value的定义如下: type Value interface { String() string // 将flag类型的值转换为string类型的值，并返回string的内容 Set(string) error // 将string类型的值转换为flag类型的值，转换失败报错 Type() string // 返回flag的类型，例如：string、int、ip等 } Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/lib/配置文件解析工具viper.html":{"url":"golang/lib/配置文件解析工具viper.html","title":"配置文件解析工具-viper包","keywords":"","body":"概述 Vipier 是一个完整的Go应用程序配置文件解析方案。它可以处理任何类型或者格式的配置文件。 源码地址: viper Vipier支持: 设置默认值。 从不同格式的配置文件中读取配置包括json,toml,yaml,hcl,envfile. 从环境变量读取配置 从第三方配置存储服务读取配置 etcd consul并且监听配置改变。 从命令行参数选项中读取配置。 从本地缓冲中读取配置 直接设置值。 Vipie读取配置文件方式的顺序从高到底为: 直接使用 set的方式设置 命令行参数 环境变量 配置文件 kv存储 默认值 [!TIP] viper配置键不区分大小写。 使用 导入包 go get github.com/spf13/viper Viper使用方式。 viper中初始化了一个全局的vipier实例。所以我们可以在导入包后直接使用viper.set等方法设置配置值。我们可以在我们的应用中直接使用这个实例。 var v *Viper func init() { v = New() ...... } 设置默认值 func main() { viper.SetDefault(\"ContentDir\", \"content\") viper.SetDefault(\"LayoutDir\", \"layouts\") fmt.Println(viper.GetString(\"contentdir\")) //ok fmt.Println(viper.GetString(\"ContentDir\")) // ok } 从配置文件读取 func main() { viper.SetConfigName(\"config\") viper.SetConfigType(\"yaml\") viper.AddConfigPath(\".\") viper.AddConfigPath(\"./config\") if err := viper.ReadInConfig(); err != nil { // 如果配置文件未找到的错误想被特殊处理 if _, ok := err.(viper.ConfigFileNotFoundError); ok { fmt.Println(\"config not found\") } else { fmt.Println(\"cofnig file cound but other errors\") panic(err) } } viper.SetDefault(\"app.name\", \"default\") fmt.Println(viper.GetString(\"app.name\")) //配置文件优先级高于默认值 fmt.Println(viper.GetStringSlice(\"app.databases\")) } 回写配置文件 一共有以下几种操作 WriteConfig 按照初始化的配置文件路径 回写配置。如果路径不存在，报错。文件存在则直接覆盖。 SafeWriteConfig 同上 路径不存在，报错。文件存在，不会覆盖。 WriteConfigAs 写入给定的文件路径下。如果文件存在，会覆盖 SafeWriteConfigAs 写入给定的文件路径下。如果文件存在，不会覆盖 不加AS,回写到viper.AddConfigPath(\".\")下的路径下。加AS,指定路径。加Safe,如果文件存在不覆盖。不加Safe，文件存在会覆盖。 //重新设置值 viper.Set(\"app.name\", \"gogogo\") //回写配置文件 viper.WriteConfig() // 回写到AddConfigPath路径中。 viper.SafeWriteConfig() viper.WriteConfigAs(\"./tpl/config.yaml\") viper.SafeWriteConfigAs(\"./tpl/config.yaml\") 配置文件热加载 func main() { viper.SetConfigName(\"config\") viper.SetConfigType(\"yaml\") viper.AddConfigPath(\".\") viper.AddConfigPath(\"./config\") if err := viper.ReadInConfig(); err != nil { // 如果配置文件未找到的错误想被特殊处理 if _, ok := err.(viper.ConfigFileNotFoundError); ok { fmt.Println(\"config not found\") } else { fmt.Println(\"cofnig file cound but other errors\") panic(err) } } viper.WatchConfig() go func() { viper.OnConfigChange(func(e fsnotify.Event) { fmt.Println(e.Name) // Users/duyong/WorkPlace/goDemo/pflagDemo/config.yaml fmt.Println(e.Op) // WRITE fmt.Println(viper.GetString(\"app.name\")) }) }() select {} } 缓存中读取 viper.SetConfigType(\"yaml\") // or viper.SetConfigType(\"YAML\") // any approach to require this configuration into your program. var yamlExample = []byte(` Hacker: true name: steve hobbies: - skateboarding - snowboarding - go clothing: jacket: leather trousers: denim age: 35 eyes : brown beard: true `) viper.ReadConfig(bytes.NewBuffer(yamlExample)) viper.Get(\"name\") // this would be \"steve\" 读取环境变量 提供的方法： AutomaticEnv() BindEnv(string...) : error SetEnvPrefix(string) SetEnvKeyReplacer(string...) *strings.Replacer AllowEmptyEnv(bool) 在处理ENV变量时，重要的是要认识到Viper将ENV变量视为区分大小写的。 Viper提供了一种机制来尝试确保ENV变量是惟一的。通过使用SetEnvPrefix，可以告诉Viper在读取环境变量时使用前缀。BindEnv和AutomaticEnv都将使用这个前缀。 func main() { viper.SetEnvPrefix(\"viper\") // 自动转为大写 // 第一个参数为键名。只有第一个参数时,环境变量默认使用 前缀_大写键名 VIPER_USERNAME viper.BindEnv(\"username\") os.Setenv(\"VIPER_USERNAME\", \"jack\") fmt.Println(viper.Get(\"username\")) // 当有第二个参数时,第二个参数为显示指定的环境变量。就叫ID. viper.BindEnv(\"id\", \"ID\") os.Setenv(\"ID\", \"123\") fmt.Println(viper.Get(\"id\")) } func main() { os.Setenv(\"VIPER_USER_NAME\", \"jack\") os.Setenv(\"VIPER_USER_AGE\", \"20\") viper.AutomaticEnv() viper.SetEnvPrefix(\"VIPER\") // viper.get时 key中的. _ - 被替换为_ viper.SetEnvKeyReplacer(strings.NewReplacer(\".\", \"_\", \"-\", \"_\")) viper.BindEnv(\"user.name\") viper.BindEnv(\"user.age\", \"USER_AGE\") fmt.Println(viper.Get(\"user.name\")) fmt.Println(viper.Get(\"user.age\")) } 与Pflag绑定使用 func main() { // 绑定单个标志 port := pflag.Int(\"port\", 1138, \"Port to run Application server on\") viper.BindPFlag(\"port\", pflag.Lookup(\"port\")) pflag.Parse() fmt.Println(*port) } func main() { // 绑定标志集 port := pflag.Int(\"port\", 1138, \"Port to run Application server on\") viper.BindPFlags(pflag.CommandLine) pflag.Parse() fmt.Println(*port) } 从远程键值对数据库读取 viper.AddSecureRemoteProvider(\"etcd\",\"http://127.0.0.1:4001\",\"/config/hugo.json\",\"/etc/secrets/mykeyring.gpg\") viper.SetConfigType(\"json\") // because there is no file extension in a stream of bytes, supported extensions are \"json\", \"toml\", \"yaml\", \"yml\", \"properties\", \"props\", \"prop\", \"env\", \"dotenv\" err := viper.ReadRemoteConfig() Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"golang/lib/命令行框架Cobra.html":{"url":"golang/lib/命令行框架Cobra.html","title":"命令行框架Cobra包","keywords":"","body":"概述 Cobra既是一个用于创建强大的现代CLI应用程序的库，也是一个用于生成应用程序和命令文件的程序。 cobra Cobra建立在commands(命令) arguments(参数) 和flags(标志)的结构之上。 好的应用程序被使用时就像在读一个句子。用户可以直观的知道如何使用他。一般有一下两种模式 APPNAME VERB NOUN --ADJECTIVE 或者 APPNAME COMMAND ARG --FLAG APPNAME 应用程序 VERB或者COMMAND 动词。程序要执行的操作。 NOUN或者ARG。 名词。非选项参数。可以代表操作作用的资源。 ADJECTIVE或者FALG。形容词。选项参数。操作资源的修饰符。 如: # server是cmd --port 是flag hugo server --port=1313 # clone是命令，url是选项参数 --bare是非选项参数 git clone URL --bare 安装 命令行安装 go install github.com/spf13/cobra/cobra@latest 安装库 go get -u github.com/spf13/cobra import \"github.com/spf13/cobra\" 目录结构 使用Cobra命令行工具时初始化的项目模板。同样在使用Cobra库时，我们最好也按照此模板来定义我们的目录格式。 ▾ appName/ ▾ cmd/ add.go your.go commands.go here.go main.go package main import ( \"{pathToYourApp}/cmd\" ) func main() { cmd.Execute() } Cobra库的使用 手动实现Cobra命令框架时,我们需要一个main文件和rootcmd文件。你也可以根据自己的需要增加其他命令。 创建rootCmd 我们通常将rootCmd放在cmd/root.go中 var rootCmd = &cobra.Command{ Use: \"hugo\", Short: \"Hugo is a very fast static site generator\", Long: `A Fast and Flexible Static Site Generator built with love by spf13 and friends in Go. Complete documentation is available at http://hugo.spf13.com`, Run: func(cmd *cobra.Command, args []string) { // Do Stuff Here }, } func Execute() { if err := rootCmd.Execute(); err != nil { fmt.Println(err) os.Exit(1) } } 我们可以通过viper和pflag(已经集成到cobra中)定义标志和配置绑定。 package cmd import ( \"fmt\" \"os\" homedir \"github.com/mitchellh/go-homedir\" \"github.com/spf13/cobra\" \"github.com/spf13/viper\" ) var rootCmd = &cobra.Command{ Use: \"hugo\", Short: \"Hugo is a very fast static site generator\", Long: `A Fast and Flexible Static Site Generator built with love by spf13 and friends in Go. Complete documentation is available at http://hugo.spf13.com`, Run: func(cmd *cobra.Command, args []string) { // Do Stuff Here }, } var ( cfgFile string projectBase string userLicense string ) func init() { cobra.OnInitialize(initConfig) rootCmd.PersistentFlags().StringVar(&cfgFile, \"config\", \"\", \"config file (default is $HOME/.cobra.yaml)\") rootCmd.PersistentFlags().StringVarP(&projectBase, \"projectbase\", \"b\", \"\", \"base project directory eg. github.com/spf13/\") rootCmd.PersistentFlags().StringP(\"author\", \"a\", \"YOUR NAME\", \"Author name for copyright attribution\") rootCmd.PersistentFlags().StringVarP(&userLicense, \"license\", \"l\", \"\", \"Name of license for the project (can provide `licensetext` in config)\") rootCmd.PersistentFlags().Bool(\"viper\", true, \"Use Viper for configuration\") viper.BindPFlag(\"author\", rootCmd.PersistentFlags().Lookup(\"author\")) viper.BindPFlag(\"projectbase\", rootCmd.PersistentFlags().Lookup(\"projectbase\")) viper.BindPFlag(\"useViper\", rootCmd.PersistentFlags().Lookup(\"viper\")) viper.SetDefault(\"author\", \"NAME HERE \") viper.SetDefault(\"license\", \"apache\") } func initConfig() { // Don't forget to read config either from cfgFile or from home directory! if cfgFile != \"\" { // Use config file from the flag. viper.SetConfigFile(cfgFile) } else { // Find home directory. home, err := homedir.Dir() if err != nil { fmt.Println(err) os.Exit(1) } // Search config in home directory with name \".cobra\" (without extension). viper.AddConfigPath(home) viper.SetConfigName(\".cobra\") } if err := viper.ReadInConfig(); err != nil { fmt.Println(\"Can't read config:\", err) os.Exit(1) } } func Execute() { if err := rootCmd.Execute(); err != nil { fmt.Println(err) os.Exit(1) } } 添加命令 可以定义其他命令，并且通常在cmd/目录中给每个命令各自的文件 假设添加一个version命令 // cmd/version.go package cmd import ( \"fmt\" \"github.com/spf13/cobra\" ) var versionCmd = &cobra.Command{ Use: \"version\", Short: \"Print the version number of Hugo\", Long: `All software has versions. This is Hugo's`, Run: func(cmd *cobra.Command, args []string) { fmt.Println(\"Hugo Static Site Generator v0.9 -- HEAD\") }, } func init() { rootCmd.AddCommand(versionCmd) } 返回错误 使用RunE回调返回错误 var versionCmd = &cobra.Command{ Use: \"version\", Short: \"Print the version number of Hugo\", Long: `All software has versions. This is Hugo's`, RunE: func(cmd *cobra.Command, args []string) error { if err := someFunc(); err != nil { return err } return nil }, } func init() { rootCmd.AddCommand(versionCmd) } func someFunc() error { return errors.New(\"version cmd is invalid\") } 同Flag一起使用 Falg提供了修饰符来控制命令如何执行。 我们可以为命令分配标志。但是由于标Flag是在不同的位置定义和使用的，所以我们需要在外部定义一个具有正确作用域的变量，以便为标记赋值 持久标志 一个标志可以是'persistent'，这意味着这个标志将对它所分配的命令以及该命令下的每个命令可用。对于全局标志，在根上指定一个标志作为持久标志。 rootCmd.PersistentFlags().BoolVarP(&Verbose, \"verbose\", \"v\", false, \"verbose output\") 本地标志 也可以在本地分配标志，该标志将只应用于该特定的命令。 localCmd.Flags().StringVarP(&Source, \"source\", \"s\", \"\", \"Source directory to read from\") 父命令的本地标志 默认情况下，Cobra只解析目标命令上的本地标志，父命令上的任何本地标志都会被忽略。通过启用命令Command.TraverseChildren。Cobra将在执行目标命令之前解析每个命令的本地标志 command := cobra.Command{ Use: \"print [OPTIONS] [COMMANDS]\", TraverseChildren: true, } 同Vipier一起使用 var author string func init() { rootCmd.PersistentFlags().StringVar(&author, \"author\", \"YOUR NAME\", \"Author name for copyright attribution\") viper.BindPFlag(\"author\", rootCmd.PersistentFlags().Lookup(\"author\")) } 在本例中，使用viper绑定持久标志author。注意:当user提供了——author标志时，变量author将不会被设置为config中的值。 标志必选 // 持久标志 rootCmd.PersistentFlags().StringVarP(&Region, \"region\", \"r\", \"\", \"AWS region (required)\") rootCmd.MarkPersistentFlagRequired(\"region\") // 本地标志 rootCmd.Flags().StringVarP(&Region, \"region\", \"r\", \"\", \"AWS region (required)\") rootCmd.MarkFlagRequired(\"region\") 非选项参数验证 在命令的过程中，经常会传入非选项参数，并且需要对这些非选项参数进行验证，Cobra 提供了机制来对非选项参数进行验证。可以使用 Command 的 Args 字段来验证非选项参数。Cobra 也内置了一些验证函数： NoArgs：如果存在任何非选项参数，该命令将报错。 ArbitraryArgs：该命令将接受任何非选项参数。 OnlyValidArgs：如果有任何非选项参数不在 Command 的 ValidArgs 字段中，该命令将报错。 MinimumNArgs(int)：如果没有至少 N 个非选项参数，该命令将报错。 MaximumNArgs(int)：如果有多于 N 个非选项参数，该命令将报错。 ExactArgs(int)：如果非选项参数个数不为 N，该命令将报错。 ExactValidArgs(int)：如果非选项参数的个数不为 N，或者非选项参数不在 Command 的 ValidArgs 字段中，该命令将报错。 RangeArgs(min, max)：如果非选项参数的个数不在 min 和 max 之间，该命令将报错。 var cmd = &cobra.Command{ Short: \"hello\", Args: func(cmd *cobra.Command, args []string) error { if len(args) 多个顶层命令例子 package main import ( \"fmt\" \"strings\" \"github.com/spf13/cobra\" ) func main() { var echoTimes int var cmdPrint = &cobra.Command{ Use: \"print [string to print]\", Short: \"Print anything to the screen\", Long: `print is for printing anything back to the screen. For many years people have printed back to the screen.`, Args: cobra.MinimumNArgs(1), Run: func(cmd *cobra.Command, args []string) { fmt.Println(\"Print: \" + strings.Join(args, \" \")) }, } var cmdEcho = &cobra.Command{ Use: \"echo [string to echo]\", Short: \"Echo anything to the screen\", Long: `echo is for echoing anything back. Echo works a lot like print, except it has a child command.`, Args: cobra.MinimumNArgs(1), Run: func(cmd *cobra.Command, args []string) { fmt.Println(\"Echo: \" + strings.Join(args, \" \")) }, } var cmdTimes = &cobra.Command{ Use: \"times [string to echo]\", Short: \"Echo anything to the screen more times\", Long: `echo things multiple times back to the user by providing a count and a string.`, Args: cobra.MinimumNArgs(1), Run: func(cmd *cobra.Command, args []string) { for i := 0; i 帮助选项和版本选项 如果在根命令上设置了version字段，Cobra会添加一个顶级的'——version'标志。使用'——version'标志运行应用程序将使用版本模板将版本打印到标准输出。模板可以通过cmd自定义。SetVersionTemplate(字符串)函数。 命令执行的钩子函数 在运行 Run 函数时，我们可以运行一些钩子函数，比如 PersistentPreRun 和 PreRun 函数在 Run 函数之前执行，PersistentPostRun 和 PostRun 在 Run 函数之后执行。如果子命令没有指定Persistent*Run函数，则子命令将会继承父命令的Persistent*Run函数。这些函数的运行顺序如下： PersistentPreRun PreRun Run PostRun PersistentPostRun package main import ( \"fmt\" \"github.com/spf13/cobra\" ) func main() { var rootCmd = &cobra.Command{ Use: \"root [sub]\", Short: \"My root command\", PersistentPreRun: func(cmd *cobra.Command, args []string) { fmt.Printf(\"Inside rootCmd PersistentPreRun with args: %v\\n\", args) }, PreRun: func(cmd *cobra.Command, args []string) { fmt.Printf(\"Inside rootCmd PreRun with args: %v\\n\", args) }, Run: func(cmd *cobra.Command, args []string) { fmt.Printf(\"Inside rootCmd Run with args: %v\\n\", args) }, PostRun: func(cmd *cobra.Command, args []string) { fmt.Printf(\"Inside rootCmd PostRun with args: %v\\n\", args) }, PersistentPostRun: func(cmd *cobra.Command, args []string) { fmt.Printf(\"Inside rootCmd PersistentPostRun with args: %v\\n\", args) }, } var subCmd = &cobra.Command{ Use: \"sub [no options!]\", Short: \"My subcommand\", PreRun: func(cmd *cobra.Command, args []string) { fmt.Printf(\"Inside subCmd PreRun with args: %v\\n\", args) }, Run: func(cmd *cobra.Command, args []string) { fmt.Printf(\"Inside subCmd Run with args: %v\\n\", args) }, PostRun: func(cmd *cobra.Command, args []string) { fmt.Printf(\"Inside subCmd PostRun with args: %v\\n\", args) }, PersistentPostRun: func(cmd *cobra.Command, args []string) { fmt.Printf(\"Inside subCmd PersistentPostRun with args: %v\\n\", args) }, } rootCmd.AddCommand(subCmd) rootCmd.SetArgs([]string{\"\"}) rootCmd.Execute() fmt.Println() rootCmd.SetArgs([]string{\"sub\", \"arg1\", \"arg2\"}) rootCmd.Execute() } 当“未知命令”发生时的建议 默认开启。如果要关闭执行: command.DisableSuggestions = true // 或者 command.SuggestionsMinimumDistance = 1 为命令生成文档 文档 简单使用 package main import ( \"log\" \"github.com/spf13/cobra\" \"github.com/spf13/cobra/doc\" ) func main() { cmd := &cobra.Command{ Use: \"test\", Short: \"my test program\", } err := doc.GenMarkdownTree(cmd, \"/tmp\") if err != nil { log.Fatal(err) } } 为整个命令树生成文档 package main import ( \"log\" \"io/ioutil\" \"os\" \"k8s.io/kubernetes/pkg/kubectl/cmd\" cmdutil \"k8s.io/kubernetes/pkg/kubectl/cmd/util\" \"github.com/spf13/cobra/doc\" ) func main() { kubectl := cmd.NewKubectlCommand(cmdutil.NewFactory(nil), os.Stdin, ioutil.Discard, ioutil.Discard) err := doc.GenMarkdownTree(kubectl, \"./\") if err != nil { log.Fatal(err) } } shell自动补全 文档 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"design/":{"url":"design/","title":"架构和设计","keywords":"","body":"Introduction 架构设计学习 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"design/微服务.html":{"url":"design/微服务.html","title":"微服务架构","keywords":"","body":"微服务与SOA的关系 SOA(Service Oriented Architecture) “面向服务的架构”。是一种设计架构的方法。其理念是每个服务以独立的形式存在于操作系统进程中。每个服务之间通过网络调用。 微服务架构: 微服务类似于SOA架构，可以看作是SOA架构的一种实现，同时也是升华。相比于SOA架构，微服务强调将服务更加的细化。将业务需要更彻底的组件化和服务化。使得业务系统拆分为可以独立开发、设计、运行的小应用。也就是微应用。这些小应用之间通过过程调用完成交互和集成。 微服务优缺点 微服务中的每个服务负责的都是单一的业务。符合架构设计的单一原则理念。微服务中的每个服务都是独立的进程,可以自动独立部署。服务间采用轻量级通信机制，可以使用不同的语言或者数据存储技术。通过使用容器编排技术 k8s等。使得服务以容器化的方式进行快速的，方便的隔离部署。 微服务从1个服务变成了多个服务。此时也会带来一些问题: 基础设施的建设复杂度变高。 解决或者跟踪问题的方式变得复杂。 必须手动处理服务之间远程调用过慢或者失败的问题。 微服务的每个服务都有自己的独立的数据库。会带来数据一致性的问题。 单个服务出问题时容易引起连锁反应导致整个服务不可用。 微服务如何落地 服务组件化 kit 一个微服务的基础库 service kit+业务代码+第三方依赖 rpc + message queue 去中心化 数据去中心化 每个服务独享自己的数据存储设置(缓存,数据库等) 治理去去中心化 技术去中心化 基础设施自动化 CI/CD 自动构建集成部署。 Testing 测试环境，单元测试，api测试 在线运行 k8s. 日志采集，报警。仪表盘等。 可用性和兼容性设计 对于可用性，要有Design For Failure思想。假设所有环节或者依赖都会失败来倒推你的设计。尽量采用粗粒度的的进程间通信(批量请求接口)。 隔离 超时控制 负载保护 限流 降级 重试 负载均衡 兼容性的设计要做到设计谨记保持服务契约(api)的兼容性Be conservative in what you send, be liberal in what you accept.发送时要保守，接收时要开放。按照伯斯塔尔法则的思想来设计和实现服务时，发送的数据要更保守， 意味着最小化的传送必要的信息，接收时更开放意味着要最大限度的容忍冗余数据，保证兼容性。 微服务如何设计 API网关的设计和演进 服务如何划分 按照公司部门或者模块划分。 DDD领域驱动设计的方式划分。 限界上下文是 DDD 中用来划分不同业务边界的元素， 这里业务边界的含义是“解决不同业务问题”的问题域 和对应的解决方案域，为了解决某种类型的业务问题， 贴近领域知识，也就是业务 CQRS 安全设计 服务外部： 网关鉴权。 限流熔断的操作。生成内部的token，传递到下一层BBF BBF 解析token 获取用户id 传递到服务层 服务层直接使用用户id 服务内部： full trust half trust zero trust 采用证书等方式实现服务的认证和授权。 服务发现 发现类型 客户端发现：直连，比服务端服务发现少一次网络跳转，Consumer 需要内置特定的服务发现客户端和发现逻辑。 服务端发现：Consumer 无需关注服务发现具体细节，只需知道服务的 DNS 域名即可，支持异构语言开发，需要基础设施支撑，多了一次网络跳转，可能有性能损失。 通过 Family(appid) 和 Addr(IP:Port) 定位实例，除此之外还可以附加更多的元数据：权重、染色标签、集群等。 Provider 注册后定期(30s)心跳一次，注册， 心跳，下线都需要进行同步，注册和下线需要进行长轮询推送。 Consumer 启动时拉取实例，发起30s长轮询 Server 定期(60s) 检测失效(90s)的实例，失效则剔除。短时间里丢失了大量的心跳连接(15分钟内心跳低于期望值*85%)，开启自我保护，保留过期服务不删除。 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"design/错误码.html":{"url":"design/错误码.html","title":"如何设计一套合理的错误码","keywords":"","body":"期望错误码实现的功能 RESTful API 是基于 HTTP 协议的一系列 API 开发规范，HTTP 请求结束后，无论 API 请求成功或失败，都需要让客户端感知到，以便客户端决定下一步该如何处理。 为了让用户拥有最好的体验，需要有一个比较好的错误码实现方式。在设计错误码时，我们希望能够实现以下功能： 每次返回不仅仅有HTTP Code码，还应该有业务Code码。 因为 HTTP Code 码有限，并且都是跟 HTTP Transport 层相关的 Code 码，所以我们希望能有自己的错误 Code 码。一方面，可以根据需要自行扩展，另一方面也能够精准地定位到具体是哪个错误。同时，因为 Code 码通常是对计算机友好的 10 进制整数，基于 Code 码，计算机也可以很方便地进行一些分支处理。当然了，业务码也要有一定规则，可以通过业务码迅速定位出是哪类错误。 考虑到安全，希望能够对外对内分别展示不同的错误信息。 当开发一个对外的系统，业务出错时，需要一些机制告诉用户出了什么错误，如果能够提供一些帮助文档会更好。但是，我们不可能把所有的错误都暴露给外部用户，这不仅没必要，也不安全。所以也需要能让我们获取到更详细的内部错误信息的机制，这些内部错误信息可能包含一些敏感的数据，不宜对外展示，但可以协助我们进行问题定位。 综上，我们需要设计的错误码应该是规范的，能方便客户端感知到 HTTP 是否请求成功，并带有业务码和出错信息 常见的错误码设计方式 假设错误消息为用户账号没有找到而请求失败的例子 不论请求成功或失败，始终返回200 http status code，在 HTTP Body 中包含用户账号没有找到的错误信息 例如 Facebook API 的错误 Code 设计，始终返回 200 http status code： { \"error\": { \"message\": \"Syntax error \\\"Field picture specified more than once. This is only possible before version 2.1\\\" at character 23: id,name,picture,picture\", \"type\": \"OAuthException\", \"code\": 2500, \"fbtrace_id\": \"xxxxxxxxxxx\" } } 采用固定返回200 http status code的方式，有其合理性。比如，HTTP Code 通常代表 HTTP Transport 层的状态信息。当我们收到 HTTP 请求，并返回时，HTTP Transport 层是成功的，所以从这个层面上来看，HTTP Status 固定为 200 也是合理的。 但是这个方式的缺点也很明显：对于每一次请求，我们都要去解析 HTTP Body，从中解析出错误码和错误信息。实际上，大部分情况下，我们对于成功的请求，要么直接转发，要么直接解析到某个结构体中；对于失败的请求，我们也希望能够更直接地感知到请求失败。这种方式对性能会有一定的影响，对客户端不友好。所以我不建议你使用这种方式。 返回http 400 错误码，并在 Body 中返回简单的错误信息。 例如：Twitter API 的错误设计，会根据错误类型，返回合适的 HTTP Code，并在 Body 中返回错误信息和自定义业务 Code。 HTTP/1.1 400 Bad Request x-connection-hash: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx set-cookie: guest_id=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Date: Thu, 01 Jun 2017 03:04:23 GMT Content-Length: 62 x-response-time: 5 strict-transport-security: max-age=631138519 Connection: keep-alive Content-Type: application/json; charset=utf-8 Server: tsa_b {\"errors\":[{\"code\":215,\"message\":\"Bad Authentication data.\"}]} 这种方式比第一种要好一些，通过http status code可以使客户端非常直接地感知到请求失败，并且提供给客户端一些错误信息供参考。但是仅仅靠这些信息，还不能准确地定位和解决问题。 返回http 400 错误码，并在 Body 中返回详细的错误信息。 例如：微软 Bing API 的错误设计，会根据错误类型，返回合适的 HTTP Code，并在 Body 中返回详尽的错误信息 HTTP/1.1 400 Date: Thu, 01 Jun 2017 03:40:55 GMT Content-Length: 276 Connection: keep-alive Content-Type: application/json; charset=utf-8 Server: Microsoft-IIS/10.0 X-Content-Type-Options: nosniff {\"SearchResponse\":{\"Version\":\"2.2\",\"Query\":{\"SearchTerms\":\"api error codes\"},\"Errors\":[{\"Code\":1001,\"Message\":\"Required parameter is missing.\",\"Parameter\":\"SearchRequest.AppId\",\"HelpUrl\":\"http\\u003a\\u002f\\u002fmsdn.microsoft.com\\u002fen-us\\u002flibrary\\u002fdd251042.aspx\"}]}} 推荐使用此种方式,既能通过http status code使客户端方便地知道请求出错，又可以使用户根据返回的信息知道哪里出错，以及如何解决问题。同时，返回了机器友好的业务 Code 码，可以在有需要时让程序进一步判断处理。 错误码设计建议 有区别于http status code的业务码，业务码需要有一定规则，可以通过业务码判断出是哪类错误。 请求出错时，可以通过http status code直接感知到请求出错。 需要在请求出错时，返回详细的信息，通常包括 3 类信息：业务 Code 码、错误信息和参考文档（可选） 。返回的错误信息，需要是可以直接展示给用户的安全信息，也就是说不能包含敏感信息；同时也要有内部更详细的错误信息，方便 debug。 返回的数据格式应该是固定的、规范的。 错误信息要保持简洁，并且提供有用的信息。 业务code码设计 在实际开发中，引入业务 Code 码有下面几个好处： 可以非常方便地定位问题和定位代码行（看到错误码知道什么意思、grep 错误码可以定位到错误码所在行、某个错误类型的唯一标识）。 错误码包含一定的信息，通过错误码可以判断出错误级别、错误模块和具体错误信息。 Go 中的 HTTP 服务器开发都是引用 net/http 包，该包中只有 60 个错误码，基本都是跟 HTTP 请求相关的错误码，在一个大型系统中，这些错误码完全不够用，而且这些错误码跟业务没有任何关联，满足不了业务的需求。引入业务的 Code 码，则可以解决这些问题。 推荐的 Code 码设计规范：纯数字表示，不同部位代表不同的服务，不同的模块。 错误代码说明：100101 10: 服务。 01: 某个服务下的某个模块。 01: 模块下的错误码序号，每个模块可以注册 100 个错误。 你可能会问：按这种设计，每个模块下最多能注册 100 个错误，是不是有点少？其实在我看来，如果每个模块的错误码超过 100 个，要么说明这个模块太大了，建议拆分；要么说明错误码设计得不合理，共享性差，需要重新设计。 设置对应的 HTTP Status Code Go net/http 包提供了 60 个错误码，大致分为如下 5 类： 1XX - （指示信息）表示请求已接收，继续处理。 2XX - （请求成功）表示成功处理了请求的状态代码。 3XX - （请求被重定向）表示要完成请求，需要进一步操作。通常，这些状态代码用来重定向。 4XX - （请求错误）这些状态代码表示请求可能出错，妨碍了服务器的处理，通常是客户端出错，需要客户端做进一步的处理。 5XX - （服务器错误）这些状态代码表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是客户端的问题。 可以看到 HTTP Code 有很多种，如果每个 Code 都做错误映射，会面临很多问题。比如，研发同学不太好判断错误属于哪种http status code，到最后很可能会导致错误或者http status code不匹配，变成一种形式。而且，客户端也难以应对这么多的 HTTP 错误码。 所以，这里建议http status code不要太多，基本上只需要这 3 个 HTTP Code: 200 - 表示请求成功执行。 400 - 表示客户端出问题。 500 - 表示服务端出问题。 如果觉得这 3 个错误码不够用，最多可以加如下 3 个错误码： 401 - 表示认证失败。 403 - 表示授权失败。 404 - 表示资源找不到，这里的资源可以是 URL 或者 RESTful 资源。 将错误码控制在适当的数目内，客户端比较容易处理和判断，开发也比较容易进行错误码映射。 错误包的封装 好的错误包可以支持 错误堆栈 支持不通的格式 如%+v、%v、%s等格式，可以根据需要打印不同丰富度的错误信息。 能支持 Wrap/Unwrap 功能，也就是在已有的错误上，追加一些新的信息 支持Is As函数 能够支持两种错误创建方式：非格式化创建和格式化创建 github.com/pkg/errors/errors.go包支持以上功能并且已经被官方吸收到go的标准库中。 现在我们希望我们自己封装的错误包除了可以支持以上功能外，还可以支持记录业务错误码。 并在打印错误堆栈时，也同时打印我们自己的业务错误码。 github.com/xiaodulala/component-tools/tree/main/pkg/errors错误包 在github.com/pkg/errors/errors.go基础上修改，新增了withCode错误类型。并且维护了一个错误码字典。调用者可以将自己的错误码注册到内存中。 调用者可以按照规范定义错误码。以注释的方式标示错误码的对应httpCode和对外暴露的错误信息。然后通过工具 github.com/xiaodulala/component-tools/tree/main/tools/codegen自动生成注册代码，注册到错误包维护的内存字典中。 新的错误包维护的业务code字典主要用来打印错误堆栈时，在内存中寻找错误码对应的httpcode和对外错误信息。 为了方便错误码更加规范和通用，预先定义了一些通用的错误码，可以直接引入github.com/xiaodulala/component-tools/tree/main/component/errorcode. 这个包也同时演示了如何定义错误码和错误码的注释格式，然后用工具直接生成。 错误码规范 通过对错误码规范的一些分析。最终确定的错误码规范如下: 错误代码： 100101 10 服务 01 模块 01 模块下的错误码序号，每个模块可以注册 100 个错误 说明: 错误码用纯数字表示。每个部分分别代表服务 模块 错误码序号。每个模块可以注册100个错误。 Code 代码从 100101 开始。1000以下为保留code 通用错误设计如下： 服务 模块 说明 10 00 通用-基本错误 10 01 通用-数据库类错误 10 02 通用-认证授权类错误 10 03 通用-编码类错误 11 01 自己服务-用户模块错误 11 02 自己服务-xx模块错误 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"cloudNative/":{"url":"cloudNative/","title":"云原生技术","keywords":"","body":"Introduction docker核心 k8s 服务网格等技术 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"cloudNative/docker核心技术.html":{"url":"cloudNative/docker核心技术.html","title":"docker的核心技术","keywords":"","body":"参考 极客时间-孟凡杰-云原生训练营 从系统架构谈起 传统的分层架构 VS 微服务 在复杂的系统中，很多开发人员对一个系统进行开发，到最后造成的结果是没有一个人完全了解整个系统。导致项目越来越难维护和升级。 后续衍生出了SOA架构,对复杂的系统进行模块化的拆分，通过企业服务总线(Enterprise Service Bus)来连接各个组件。这样做的后果是ESB又成为了一个单体架构，越来越大导致不可维护。 到现在最新的微服务架构。微服务架构其实是SOA架构的一种实现。同时也是升华。相比于SOA架构，微服务强调将服务更加的细化。将业务需要更彻底的组件化和服务化。使得业务系统拆分为可以独立开发、设计、运行的小应用，且每个应用之间都通过过程调用等轻量级的通信方式完成交互。 微服务之间的通信方式 点对点的方式 多用于系统内部组件之间通讯 有大量的重复模块如认证授权 缺少统一的规范，如监控审计。 后期维护成本高，服务和服务之间的关系错综复杂难以理解。 api网关 基于一个轻量级的消息网关 对下层微服务公共部分进行整合。认证 授权 监控 限流 熔断等。 理解Dcoekr docker的由来 基于 Linux 内核的 Cgroup，Namespace，以及 Union FS 等技术，对进程进行封装隔离，属于操作系统 层面的虚拟化技术，由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。 最初实现是基于 LXC，从 0.7 以后开始去除 LXC，转而使用自行开发的 Libcontainer，从 1.11 开始，则 进一步演进为使用 runC 和 Containerd。 Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容 器的创建和维护，使得 Docker 技术比虚拟机技术更为轻便、快捷。 为什么用Docker 更高效的利用系统资源 更快速的启动时间 一致的运行环境 持续交付和部署 更轻松的迁移 更轻松的维护和扩展 运行态对比: 性能对比: 最后: 容器是操作系统层面的虚拟化技术，docker是基于容器技术实现的一种产品。由于docker的出现，把容器这个概念带火了。后来就把docker和容器等价了。其实并不是。 容器的主要特性 Namespace Linux Namespace 是一种Linux Kernel提供的资源隔离方案。系统可以为进程分配不同的Namespace，并保证不通的Namespace资源独立分配，进程彼此隔离，不同的Namespace下的进程互不干扰。 Linux对Namespace的操作方法 clone 在创建新的进程系统调用时，可以通过flag参数指定需要新建的Namespace类型 setns 该系统调用可以让调用进程加入某个已存在的Namespace中 unshare 该系统调用可以调用进程移动到新的Namespace下 Namespace 隔离性 pid namespace 不同用户的进程就是通过 Pid namespace 隔离开的，且不同 namespace 中可以有相同 Pid。 有了 Pid namespace, 每个 namespace 中的 Pid 能够相互隔离。 net namespace 网络隔离是通过 net namespace 实现的， 每个 net namespace 有独立的 network devices, IP addresses, IP routing tables, /proc/net 目录。Docker 默认采用 veth 的方式将 container 中的虚拟网卡同 host 上的一个 docker bridge: docker0 连接 在一起。 ipc namespace Container 中进程交互还是采用 linux 常见的进程间交互方法 (interprocess communication – IPC), 包 括常见的信号量、消息队列和共享内存。container 的进程间交互实际上还是 host上 具有相同 Pid namespace 中的进程间交互，因此需要在 IPC 资源申请时加入 namespace 信息 - 每个 IPC 资源有一个唯一的 32 位 ID mnt namespace mnt namespace 允许不同 namespace 的进程看到的文件结构不同，这样每个 namespace 中的进程所看 到的文件目录就被隔离开了。 uts namespace UTS(“UNIX Time-sharing System”) namespace允许每个 container 拥有独立的 hostname 和 domain name, 使其在网络上可以被视作一个独立的节点而非 Host 上的一个进程 user namespace 每个 container 可以有不同的 user 和 group id, 也就是说可以在 container 内部用 container 内部的用户 执行程序而非 Host 上的用户。 Namespace 常用操作 查看当前系统的 namespace: lsns –t 查看某进程的 namespace: ls -la /proc//ns/ 进入某 namespace 运行命令: nsenter -t -n ip addr CGroup Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"software/":{"url":"software/","title":"软件安装和使用","keywords":"","body":"Introduction 软件安装和使用篇 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"software/GitBook搭建并且关联到GitHub.html":{"url":"software/GitBook搭建并且关联到GitHub.html","title":"GitBook搭建并且关联到GitHub Pages","keywords":"","body":"概览 -- 记录一次使用gitbook写电子书,并且将源码推送到github仓库。最后通过github action自动构建电子书并且发布的过程。 最终效果: 本地编辑文章,生成md文件。push到github仓库，就可以在线通过自定义域名浏览文章。如: 我的笔记本 自动发布书籍的方式 我使用的是第二种方式,这里介绍一下两种方式 1. gitbook在线构建 gitbook 允许你使用md文档的语法，构建出精美的电子书。 gitbook是一个文档或者是电子书托管平台，官方站点就是 gitbook。是一个线上环境。 gitbook也是一个基于node.js的命令行工具。gitbook工具允许我们在本地快速构建书籍结构，下载插件，构建电子书并且支持启动本地web服务来浏览本地的电子书。 这里说一下使用gitbook线上环境自动发布书籍的逻辑: 首先gitbook线上环境允许你在线创建自己的文档,使用md的方式对文档进行编辑。 允许对外发布,分两种方式 1.允许搜索引擎爬取 2.不允许搜索引擎爬取。 对外发布的Space或者是Collection可以绑定自定义的域名,让用户访问。 在线的gitbook仓库也可以和github仓库关联,互相同步。 所以,如果使用gitbook线上环境自动发布书籍,可以这样做: 使用gitbook-cli创建本地书籍 登录gitbook账号,创建Space或者是Collection 创建你的github仓库,用来存储数据源文件。 gitbook仓库与github仓库绑定,授权同步。 这样我们就可以本地写文章,然后推送到github,绑定的仓库有更新时,gitbook会自动从github同步你的源文件。gitbook属于线上环境,会自动构建,安装插件。然后就可以访问了。 这是一种自动发布的方式,但自己的部署的时候碰到一些问题： 网站有时候不能访问，需要fq。 本地构建书籍时,插件可用。推送到线上后,gitbook构建出来的书籍格式很多插件没有被使用。导致书籍体验很不好。例如：目录插件不生效等...。目前还没发现哪里配置的有问题。 所以没有使用这种自动发布的方式,不使用gitbook在线环境，使用的是github的 pages。 2. github pages GitHub Pages是免费的静态站点，三个特点：免费托管、自带主题、支持自制页面和Jekyll。 静态页面我们依然使用gitbook工具生成。然后按照以下步骤完成书籍自动发布: 安装gitbook工具,本地生成电子书。 安装一些gitbook插件,本地启动服务查看效果。 关联github仓库 创建github pages 使用github action自动构建电子书,并且发布到github pages github pages绑定自定义域名 这种自动发布方式与上面的方式不同点是: 我们相当于是将\"本地\"构建好的完整书籍项目推送到了gh-pages分支。而不是推送源码后在线上构建。 \"本地\"加了引号是因为，当我们使用了github action时, github会提供CI环境为我们进行构建并且将构建好的项目推送到指定分支。所以并不需要你真的每次都在本地构建,然后推送。其实,你每次推送的还是源码文件,剩下的全部都是自动执行。 GitBook命令工具 安装 npm install -g gitbook-cli gitbook -V gitbook ls # 按照提示装好版本 gitook命令使用 gitbook help # 查看帮助 gitbook init [book]。 初始化电子书。会在你指定目录下生成README和SUMMARY gitbook install 安装book.json指定的插件 gitbook build 构建书籍。生成的静态文件在_book中 gitbook serve 启动本地服务,查看电子书 # 还有一些导出书籍命令，可通过帮助文档查看。 书籍构建结构 这里介绍一下构建书籍的目录结构和文件说明 ├── .bookignore # gitbook忽略文件。主要用来指定 gitbook build时不打包到_book的文件 ├── .git ├── .github # github action 工作流目录 ├── .gitignore # 提交到github仓库忽略的文件 ├── README.md # 书籍介绍 ├── SUMMARY.md # 书籍目录 ├── _book # 构建出来的静态文件。此文件夹内就是我们要发布到pages的静态资源 ├── book.json # gitbook配置文件 ├── golang # 自定义的书籍目录 ├── img # 文章图片 ├── node_modules # 插件目录 └── sortware # 自定义的书籍目录 目录文件构建方式 # Summary * [Introduction](README.md) * [Golang](golang/README.md) * [Go语言核心](golang/kernel/README.md) * [Go语言如何测试](golang/kernel/Go语言测试.md) * [Go语言三方库](golang/lib/README.md) * [Test包](golang/lib/aa.md) * [Go经典面试题](golang/question/README.md) * [软件安装和使用](software/README.md) * [GitBook搭建并且关联到GitHub Pages](software/GitBook搭建并且关联到GitHub.md) 每个文件件下要有自己的README文件。 目录文件夹下不能再有目录。不支持书籍嵌套。 插件配置 \"plugins\": [ \"back-to-top-button\", \"chapter-fold\", \"expandable-chapters-small\", \"code\", \"copy-code-button\", \"-lunr\", \"-search\", \"search-pro\", \"advanced-emoji\", \"github\", \"splitter\", \"page-toc-button\", \"alerts\", \"flexible-alerts\", \"pageview-count\", \"auto-scroll-table\", \"popup\", \"tbfed-pagefooter\" ], \"pluginsConfig\": { \"github\": { \"url\": \"https://github.com\" }, \"tbfed-pagefooter\": { \"copyright\":\"Copyright &copy Du Yong \", \"modify_label\": \"该文件修订时间：\", \"modify_format\": \"YYYY-MM-DD HH:mm:ss\" }, \"page-toc-button\": { \"maxTocDepth\": 2, \"minTocSize\": 2 } } 插件可以参考这边文章 GitBook插件整理 github pages配置 官网介绍 关于 GitHub Pages GitHub Pages 是一项静态站点托管服务，它直接从 GitHub 上的仓库获取 HTML、CSS 和 JavaScript 文件，（可选）通过构建过程运行文件，然后发布网站。 您可以在 GitHub Pages 示例集合中查看 GitHub Pages 站点的示例。 站点类型: 组织 要发布组织站点，必须创建名为 .github.io 的组织所拥有的仓库 用户 要发布用户站点，必须创建用户帐户所拥有的名为 .github.io 项目 项目站点源文件和项目本身存储在一个仓库中。在不使用自定义域名的情况下,项目站点访问http(s)://.github.io/ 我采用项目站点类型。因为项目站点可以有多个。而个人或者组织站点只能有一个。 新建仓库 gitbook-note 关联本地仓库 git init git remote add origin git@github.com:xiaodulala/gitbook-note.git # 推送到github仓库 注意,要将_book node_modules两个文件夹的内容忽略掉。只提交书籍的源文件。不要提交构建出来的静态资源文件和下载的插件。 git push origin master 构建书籍 # 使用build 构建书籍。默认目录为_book. 注意我们不希望构建出来的静态目录有一些其他的文件。要选择忽略掉。 编写.bookignore 忽略一些文件： .gitignore .github .bookignore #构建 gitbook build 创建远程分支gh-pages分支.并与本地静态资源仓库matser分支关联 cd _book git init git remote add origin git@github.com:xiaodulala/gitbook-note.git git push --force --quiet \"git@github.com:xiaodulala/gitbook-note.git\" master:gh-pages 以上操作后,我们可以在仓库设置中的page页面查看访问地址。 到目前为止,是我们手动构建的。接着要把构建并发布自动化。使用github actions. github actions配置 github actions 是github上用来持续集成和部署的功能。 每次持续继承偶读需要拉取代码、跑测试用例、合并分支、服务部署和发布等操作。github就把这些操作称为actions. github允许开发者把每个操作写成独立的脚本，存放到代码仓库里。供其他人引用。所以，当我们的项目需要使用github actions时，就不需要编写复杂的从0开始的脚本。我们可以直接引用别人写好的actions. github actions 官方市场 gitbook的发布我选用了 这一个插件。 工作流文件如下: name: Build and Publish My GitBook on: workflow_dispatch: push: branches: - master jobs: build: name: Build Gitbook runs-on: ubuntu-latest steps: # Check out the repo first - name: Checkout code uses: actions/checkout@v2 # Run this action to publish gitbook - name: Publish uses: tuliren/publish-gitbook@v1.0.0 with: # specify either github_token or personal_token github_token: ${{ secrets.GITHUB_TOKEN }} # personal_token: ${{ secrets.PERSONAL_TOKEN }} 这样，我们就可以在本地推送源文件后，自动发布了。你可以在github的action选项中查看构建过程和结果。 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"software/docker&docker-compose安装.html":{"url":"software/docker&docker-compose安装.html","title":"docker&docker-compose安装","keywords":"","body":"[TOC] docker 安装 根据操作系统安装(需提供外网)官方文档: docker安装 centos # 1.卸载 sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine # 2. Enable the nightly or test repositories. sudo yum install -y yum-utils sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum-config-manager --enable docker-ce-nightly sudo yum-config-manager --enable docker-ce-test # 3. 查看版本 安装 yum list docker-ce --showduplicates | sort -r sudo yum install docker-ce- docker-ce-cli- containerd.io # sudo yum install docker-ce docker-ce-cli containerd.io 安装最新 # 4. 启动 sudo systemctl start docker sudo systemctl enable docker # 5. 验证 sudo docker run hello-world ubuntu # 1. 卸载 sudo apt-get remove docker docker-engine docker.io containerd runc # 2. Set up the repository sudo apt-get update sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg \\ lsb-release # Add Docker’s official GPG key: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg # To add the nightly or test repository echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null # 3. 版本列表 安装 sudo apt-get update apt-cache madison docker-ce sudo apt-get install docker-ce= docker-ce-cli= containerd.io # sudo apt-get install docker-ce docker-ce-cli containerd.io 最新版本 # 4. 验证 sudo docker run hello-world Manage Docker as a non-root user # 1. Create the docker group. sudo groupadd docker # 2.Add your user to the docker group. sudo usermod -aG docker $USER # 3. Log out and log back in so that your group membership is re-evaluated. newgrp docker Configure Docker to start on boot sudo systemctl enable docker.service sudo systemctl enable containerd.service 加速 sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json docker-compose 安装 二进制下载 脚本安装 sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose 卸载 sudo yum remove docker-ce docker-ce-cli containerd.io sudo rm -rf /var/lib/docker sudo rm -rf /var/lib/containerd 问题 centos 3.10.0-229.7.2.el7.x86_64 这个版本 只要安装最新的docker,端口映射无法访问。 安装旧版本 sudo yum -y --downloadonly update sudo yum install -y yum-utils device-mapper-persistent-data lvm2 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo sudo yum -y install docker-ce-18.03.1.ce # 剩下都一样 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"software/docker-compose安装软件.html":{"url":"software/docker-compose安装软件.html","title":"docker-compose启动应用","keywords":"","body":"Mysql 创建目录 # 创建目录 mkdir -p mysql/datadir mysql/conf mysql/mydir Mysql配置文件 vim ./mysql/conf/my.cnf [mysqld] user=mysql default-storage-engine=INNODB #character-set-server=utf8 character-set-client-handshake=FALSE character-set-server=utf8mb4 collation-server=utf8mb4_unicode_ci init_connect='SET NAMES utf8mb4' # 主从时使用 server_id=1 # 开启binlog 按需开启。影响性能 log-bin=mysql-bin # 行模式(5.7默认) binlog_format=row # binlog同步事务数(5.7默认) sync_binlog=1 skip-grant-tables [client] #utf8mb4字符集可以存储emoji表情字符 #default-character-set=utf8 default-character-set=utf8mb4 [mysql] #default-character-set=utf8 default-character-set=utf8mb4 docker-compose.yaml version: '3' services: dy_mysql: restart: always image: mysql:5.7 container_name: dy_mysql volumes: - ./mydir:/mydir - ./datadir:/var/lib/mysql - ./conf/my.cnf:/etc/my.cnf environment: - MYSQL_ROOT_PASSWORD=duyong - TZ=Asia/Shanghai ports: - 3306:3306 修改密码 # 进入容器 docker exec -it dy_mysql bash # 进入mysql mysql # 修改密码 mysql>update mysql.user set authentication_string=password('duyong') where user='root'; # 允许root远程连接(看需要设置) grant all privileges on *.* to 'root'@'%' identified by 'duyong' with grant option; flush privileges; # 退出容器 删除配置中的skip-grant-tables 重启容器 Postgres + pgadmin4 创建目录 mkdir -p postgres/data docker-compose.yaml version: '3.1' services: postgres: container_name: duyong_postgres image: postgres:12.9 restart: always environment: POSTGRES_USER: root POSTGRES_PASSWORD: root POSTGRES_DB: duyong ports: - 5432:5432 volumes: - ./data:/var/lib/postgresql/data pgadmin4: container_name: duyong_pgadmin4 image: dpage/pgadmin4 restart: always environment: PGADMIN_DEFAULT_EMAIL: admin@fskj.com PGADMIN_DEFAULT_PASSWORD: 123 ports: - 18080:80 zookeeper单机集群 创建目录 mkdir -p zk docker-compose.yaml version: '3.1' services: zoo1: image: zookeeper restart: always hostname: zoo1 ports: - 2181:2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo2: image: zookeeper restart: always hostname: zoo2 ports: - 2182:2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo3: image: zookeeper restart: always hostname: zoo3 ports: - 2183:2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 查看集群状态 # 进入容器 docker exec -it zk-single_zoo1_1 bash # ./bin/zkServer.sh status Using config: /conf/zoo.cfg Client port found: 2181. Client address: localhost. Client SSL: false. Mode: follower zookeeper多机集群 机器 节点 ip zk node1 10.0.0.99 zk1 node2 10.0.0.100 zk2 node3 10.0.0.101 zk3 分别创建目录 # 99 mkdir -p zk1 #100 mkdir -p zk2 #101 mkdir -p zk3 docker-compose.yaml # 10.0.0.99 version: '3.1' services: zoo: image: zookeeper restart: always hostname: zoo1 ports: - 2181:2181 - 2888:2888 - 3888:3888 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=10.0.0.100:2888:3888;2181 server.3=10.0.0.101:2888:3888;2181 # 10.0.0.100 version: '3.1' services: zoo: image: zookeeper restart: always hostname: zoo2 ports: - 2181:2181 - 2888:2888 - 3888:3888 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=10.0.0.99:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=10.0.0.101:2888:3888;2181 # 10.0.0.101 version: '3.1' services: zoo: image: zookeeper restart: always hostname: zoo3 ports: - 2181:2181 - 2888:2888 - 3888:3888 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=10.0.0.99:2888:3888;2181 server.2=10.0.0.100:2888:3888;2181 server.3=zoo3:2888:3888;2181 ZK+Kafka单机集群 创建资源目录 mkdir -p kafka-single docker-compose.yaml version: '3.1' services: zoo1: image: zookeeper restart: always hostname: zoo1 ports: - 2181:2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo2: image: zookeeper restart: always hostname: zoo2 ports: - 2182:2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 zoo3: image: zookeeper restart: always hostname: zoo3 ports: - 2183:2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181 kafka1: image: wurstmeister/kafka restart: always hostname: kafka1 container_name: kafka1 ports: - 9092:9092 environment: KAFKA_ADVERTISED_HOST_NAME: kafka1 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2182,zoo3:2183 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092 KAFKA_LISTENERS: PLAINTEXT://kafka1:9092 KAFKA_DEFAULT_REPLICATION_FACTOR: 2 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2 volumes: - ./kafka1/logs:/kafka kafka2: image: wurstmeister/kafka restart: always hostname: kafka2 container_name: kafka2 ports: - 9093:9092 environment: KAFKA_ADVERTISED_HOST_NAME: kafka2 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2182,zoo3:2183 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9092 KAFKA_LISTENERS: PLAINTEXT://kafka2:9092 KAFKA_DEFAULT_REPLICATION_FACTOR: 2 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2 volumes: - ./kafka2/logs:/kafka kafka3: image: wurstmeister/kafka restart: always hostname: kafka3 container_name: kafka3 ports: - 9094:9092 environment: KAFKA_ADVERTISED_HOST_NAME: kafka3 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2182,zoo3:2183 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9092 KAFKA_LISTENERS: PLAINTEXT://kafka3:9092 KAFKA_DEFAULT_REPLICATION_FACTOR: 2 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2 volumes: - ./kafka3/logs:/kafka 测试集群 # 生产者 docker exec -it kafka1 bash # 创建topic kafka-topics.sh --create --zookeeper 10.0.0.99:2181 --replication-factor 1 --partitions 1 --topic test1 # 容器1发送消息 kafka-console-producer.sh --broker-list 10.0.0.99:9092 --topic test1 # 进入kakfa2容器查看消息 docker exec -it kafka2 bash kafka-console-consumer.sh --bootstrap-server 10.0.0.99:9092 --topic test1 --from-beginning Kafka多机集群 和多机zk配合使用 # 10.0.0.99 version: '3.1' services: kafka1: image: wurstmeister/kafka restart: always hostname: kafka1 container_name: kafka1 ports: - 9092:9092 environment: KAFKA_BROKER_ID: 1 KAFKA_ADVERTISED_HOST_NAME: 10.0.0.99 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: 10.0.0.99:2181,10.0.0.100:2181,10.0.0.101:2181 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://10.0.0.99:9092 KAFKA_LISTENERS: PLAINTEXT://kafka1:9092 KAFKA_DEFAULT_REPLICATION_FACTOR: 2 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2 volumes: - ./logs:/kafka # 10.0.0.100 version: '3.1' services: kafka2: image: wurstmeister/kafka restart: always hostname: kafka2 container_name: kafka2 ports: - 9092:9092 environment: KAFKA_BROKER_ID: 2 KAFKA_ADVERTISED_HOST_NAME: 10.0.0.100 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: 10.0.0.99:2181,10.0.0.100:2181,10.0.0.101:2181 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://10.0.0.100:9092 KAFKA_LISTENERS: PLAINTEXT://kafka2:9092 KAFKA_DEFAULT_REPLICATION_FACTOR: 2 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2 volumes: - ./logs:/kafka # 10.0.0.101 version: '3.1' services: kafka3: image: wurstmeister/kafka restart: always hostname: kafka3 container_name: kafka3 ports: - 9092:9092 environment: KAFKA_BROKER_ID: 3 KAFKA_ADVERTISED_HOST_NAME: 10.0.0.101 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: 10.0.0.99:2181,10.0.0.100:2181,10.0.0.101:2181 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://10.0.0.101:9092 KAFKA_LISTENERS: PLAINTEXT://kafka3:9092 KAFKA_DEFAULT_REPLICATION_FACTOR: 2 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2 volumes: - ./logs:/kafka NSQ 单机部署 version: '3' services: nsqlookupd_0: image: nsqio/nsq command: /nsqlookupd --broadcast-address=10.3.1.127 --tcp-address=:14160 --http-address=:14161 restart: always ports: - \"14160:14160\" - \"14161:14161\" nsqlookupd_1: image: nsqio/nsq command: /nsqlookupd --broadcast-address=10.3.1.127 --tcp-address=:14170 --http-address=:14171 restart: always ports: - \"14170:14170\" - \"14171:14171\" nsqd_0: image: nsqio/nsq command: /nsqd --broadcast-address=10.3.1.127 --tcp-address=:14150 --http-address=:14151 --lookupd-tcp-address=10.3.1.127:14160 --lookupd-tcp-address=10.3.1.127:14170 depends_on: - nsqlookupd_0 - nsqlookupd_1 ports: - \"14150:14150\" - \"14151:14151\" restart: always volumes: - /home/duyong/dy_work/docker_data/nsq_simple/0_nsqd_data:/data nsqd_1: image: nsqio/nsq command: /nsqd --broadcast-address=10.3.1.127 --tcp-address=:14140 --http-address=:14141 --lookupd-tcp-address=10.3.1.127:14160 --lookupd-tcp-address=10.3.1.127:14170 depends_on: - nsqlookupd_0 - nsqlookupd_1 ports: - \"14140:14140\" - \"14141:14141\" restart: always volumes: - /home/duyong/dy_work/docker_data/nsq_simple/1_nsqd_data:/data nsqd_2: image: nsqio/nsq command: /nsqd --broadcast-address=10.3.1.127 --tcp-address=:14130 --http-address=:14131 --lookupd-tcp-address=10.3.1.127:14160 --lookupd-tcp-address=10.3.1.127:14170 depends_on: - nsqlookupd_0 - nsqlookupd_1 ports: - \"14130:14130\" - \"14131:14131\" restart: always volumes: - /home/duyong/dy_work/docker_data/nsq_simple/2_nsqd_data:/data nsqadmin: image: nsqio/nsq command: /nsqadmin --lookupd-http-address=nsqlookupd:14161 --lookupd-http-address=nsqlookupd:14171 depends_on: - nsqlookupd_0 - nsqlookupd_1 ports: - \"4171:4171\" restart: always Redis version: '3' services: redis: image: redis:latest container_name: duyong_redis volumes: - ./data:/data - ./redis.conf:/usr/local/etc/redis/redis.conf - ./logs:/logs ports: - 6379:6379 restart: always Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"software/数据源实时同步中间件之canal和Maxwell.html":{"url":"software/数据源实时同步中间件之canal和Maxwell.html","title":"数据源实时同步中间件之canal和Maxwell","keywords":"","body":"介绍 数据实时同步有很多种方法,其中一种叫CDC。 CDC(Change Data Capture)是变更数据捕获简称。这种方法可以基于增量日志，以极低的侵入性完成增量数据捕获的工作。核心思想是: 监测并捕获数据库的变动(包括数据或者数据表的插入、更新、以及删除等)。将这些变更按照发生的顺序完成记录下来,写入到消息中间件以供其他服务进行订阅和消费。 简单来讲：CDC是指从源数据库捕获到数据和数据结构(也称为模式)的增量变更，近乎实时地将这些变更，传播到其他数据库或应用程序之处。 通过这种方式，CDC能够向数据仓库提供高效、低延迟的数据传输，以便信息被及时转换并交付给专供分析的应用程序。 与批量复制相比，变更数据的捕获通常具有如下优势: CDC通过仅发送增量的变更，来降低通过网络传输数据的成本。 CDC可以帮助用户根据最新的数据做出更快、更准确的决策。例如，CDC会将事务直接传输到专供分析的应用上。 CDC最大限度地减少了对于生产环境网络流量的干扰。 CDC中间件工具对比 目前常用的工具有如下几种: 特色 Canal Maxwell mysql_staram go-mysql-transfer 开发语言 java(阿里) java(外国) python golang 活跃度 活跃 活跃 - - 高可用 支持 支持(断点还原功能) 支持 支持 数据落地 定制 Kafka，Kinesis、RabbitMQ、Redis、Go ogle Cloud Pub/Sub、文件等) Kafka等(MQ) Redis、MongoDB、Elasticsearch、RabbitMQ、Kafka、RocketMQ、HTTP API 等 分区 支持 支持 - - 引导 不支持 支持 - - 数据格式 定制 json json json 文档 详细 详细 - - 现在用的最多的工具为canal和maxwell. 其他两种工具需要继续调研。 canalmaxwell canal属于比较重。服务端需要一个客户端来配合使用。需要用户自己定制的数据落地方式和数据格式方式。自由的同时也增加了开发量。 maxwell 属于轻量级的服务。服务端+客户端为一体。高可用的方式使用的是断点还原的方法。并且支持数据引导。 可以根据不同的应用场景进行选择。如果不是非常大型的并且定制化要求很高的服务。推荐使用maxwell Maxwell的使用 配置Mysql 修改配置文件 [mysqld] server_id=1 log-bin=master binlog_format=row sync_binlog=1 验证 mysql> show variables like \"%binlog%\"; mysql> show variables like '%server_id%'; mysql> show variables like '%log_bin%'; 创建maxwell用户并赋予权限。主要用来记录binlog同步点。 mysql> CREATE USER 'maxwell'@'%' IDENTIFIED BY 'duyong'; mysql> GRANT ALL ON maxwell.* TO 'maxwell'@'%'; mysql> GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* TO 'maxwell'@'%'; mysql> flush privileges; 启动测试的maxwell 测试 docker run -it --rm zendesk/maxwell bin/maxwell --user=maxwell\\ --password=duyong --host=10.0.0.99 --producer=stdout docker run -it --rm zendesk/maxwell bin/maxwell --user=maxwell\\ --password=duyong --host=10.0.0.100 --producer=stdout 安装kafka集群 docker 安装zookeeper集群 # 10.0.0.99 version: '3.1' services: zoo1: image: zookeeper restart: always hostname: zoo1 ports: - 2181:2181 - 2888:2888 - 3888:3888 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=10.0.0.100:2888:3888;2181 server.3=10.0.0.101:2888:3888;2181 # 10.0.0.100 version: '3.1' services: zoo1: image: zookeeper restart: always hostname: zoo2 ports: - 2181:2181 - 2888:2888 - 3888:3888 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=10.0.0.99:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=10.0.0.101:2888:3888;2181 # 10.0.0.101 version: '3.1' services: zoo1: image: zookeeper restart: always hostname: zoo3 ports: - 2181:2181 - 2888:2888 - 3888:3888 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=10.0.0.99:2888:3888;2181 server.2=10.0.0.100:2888:3888;2181 server.3=zoo3:2888:3888;2181 docker 安装kafka集群 docker-compose启动应用 docker启动maxwell并使用kafka docker run -it --rm zendesk/maxwell bin/maxwell --user=maxwell\\ --password=duyong --host=10.0.0.99 --producer=kafka \\ --kafka.bootstrap.servers=10.0.0.99:9092,10.0.0.100:9092,10.0.0.101:9092 --kafka_topic=maxwell # 后台启动 docker run -it --name=maxwell -d zendesk/maxwell bin/maxwell --user=maxwell --password=duyong --host=10.0.0.246 --port=13306 --producer=kafka --kafka.bootstrap.servers=10.0.0.247:9092,10.0.0.248:9092,10.0.0.230:9092 --kafka_topic=maxwell docker run -it --rm zendesk/maxwell bin/maxwell --user=maxwell\\ --password=duyong --host=10.0.0.100 --producer=kafka \\ --kafka.bootstrap.servers=10.0.0.99:9092,10.0.0.100:9092,10.0.0.101:9092 --kafka_topic=maxwell # 后台启动 docker run -it --name=maxwell -d zendesk/maxwell bin/maxwell --user=maxwell --password=duyong --host=10.0.0.246 --port=13306 --producer=kafka --kafka.bootstrap.servers=10.0.0.247:9092,10.0.0.248:9092,10.0.0.230:9092 --kafka_topic=maxwell Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"software/数据库审计.html":{"url":"software/数据库审计.html","title":"数据库审计插件","keywords":"","body":"背景 数据库审计是数据库安全中很重要的一个环节。 举一个和我们工作很贴近的例子，比如某一个业务在某个时间点出现了异常，因为异常操作（比如DDL）导致系统出现了严重的问题，这个时候如果要查看这个问题的具体情况，谁登陆了系统，什么时候登陆的，做了什么操作等等。 当然，开审计的功能势必会影响性能，如果不开又会有遗漏。但是为了防患于未然，把问题都扼杀在摇篮之中，通过这种规范和制度来做最后一道防线，数据库审计还是非常有必要的。 审计作用 主要将用户对数据库的各类操作行为记录审计日志，以便日后进行跟踪、查询、分析，以实现对用户操作的监控和审计。 Mysql审计工具 名称 文档 说明 mysql-audit https://github.com/mcafee/mysql-audit 开源插件,由macfee(迈克菲)公司贡献。有名的安全公司 mysql-sniffer https://github.com/Qihoo360/mysql-sniffer/blob/master/README_CN.md 基于流量的数据库审计，通过MySQL 协议进行抓包记录审计日志。不影响数据库服务器性能，不用苦口婆心的劝数据库管理员安装监控软件。由国内安全公司360贡献。 server_audit https://mariadb.com/kb/en/mariadb-audit-plugin-installation/ MariaDB 开源插件，由于Mysql和MariaDB属于同源的开源软件，也可以使用，但是要找合适的版本 mysql-audit 介绍 官方文档: https://github.com/mcafee/mysql-audit/wiki/Installation MySQL审计插件是一个来自McAfee的MySQL插件，为MySQL提供审计功能，设计的重点是安全性和审计需求。该插件可以作为独立的审计解决方案使用，也可以配置为向外部监控工具提供数据 安装 Mysql二进制 插件下载地址： https://github.com/mcafee/mysql-audit/releases. 注意选择对应的mysql版本。 查看mysql插件目录 show global variables like 'plugin_dir'; +---------------+------------------------+ | Variable_name | Value | +---------------+------------------------+ | plugin_dir | /usr/lib/mysql/plugin/ | +---------------+------------------------+ 1 row in set (0.00 sec) 解压插件拷贝到插件目录下 unzip audit-plugin-mysql-5.7-1.1.10-980-linux-x86_64.zip # 拷贝到插件目录 cp ./audit-plugin-mysql-5.7-1.1.10-980/lib/libaudit_plugin.so /usr/lib/mysql/plugin cp ./audit-plugin-mysql-5.7-1.1.10-980/utils/offset-extract.sh dy_mysql: 安装插件 需要说明：安装方式有两种，一种是使用配置文件方式，另一种是命令方式。 官方建议生产环境使用配置文件方式。打开映射的配置文件my.cnf，增加配置: [mysqld] plugin-load=AUDIT=libaudit_plugin.so 重启mysql 验证 show global status like 'AUDIT_version'; docker 方式 docker 启动: docker run -d --name mysql-audit -p 13306:3306 -v $(pwd)/datadir:/opt/mysql/data -v $(pwd)/conf/my.cnf:/etc/my.cnf harbor.sxidc.com/yfhub/mysql/audit:latest docker-compose.yalm version: '3' services: dy_mysql: restart: always image: harbor.sxidc.com/yfhub/mysql/audit:latest container_name: mysql-audit volumes: - ./datadir:/opt/mysql/data - ./conf/my.cnf:/etc/my.cnf ports: - 23306:3306 第一次启动修改root密码 # 登录容器 docker exec -it mysql-audit bash # 查看临时密码 cat /var/log/mysql/error.log | grep \"temporary password\" 2022-03-23T15:01:55.616902+08:00 1 [Note] A temporary password is generated for root@localhost: pjee-7%9;Ksd # 登录mysql mysql -uroot -p # 修改root密码 alter user user() identified by \"duyong\"; # 查看插件版本,确保插件安装 show global status like 'AUDIT_version'; 审计日志目录 cat $(pwd)/datadir/mysql-audit.json mysql-sniffer 基于流量的数据库审计，因为它不需要更改网络结构，并且也是最关键的是，不影响数据库服务器性能，不用苦口婆心的劝数据库管理员安装监控软件。它可以比较好的发现通过Web漏洞的拖库行为，以及基于数据库通讯协议的数据库管理过程中的违规行为。 ySQL Sniffer。MySQLSniffer是一个基于MySQL协议的抓包工具，实时抓取请求，并格式化输出。输出内容包括访问时间、访问用户、来源IP、访问 Database、命令耗时、返回数据行数、执行语句等。 下载安装 可以直接查看说明文档，自己进行编译安装。我这里偷懒了，直接从docker仓库中找一个别人编译好的环境，然后将可执行文件拷贝出来使用。 docker pull sliceoflife07/mysql-sniffer docker run -it -d --name sniffer sliceoflife07/mysql-sniffer sudo docker cp sniffer:/root/mysql-sniffer/proj/bin/mysql-sniffer ./ # 启动 sudo ./mysql-sniffer -i vethf5b5af3 -p 3306 # 如果是docker启动的mysql,最好是找到容器的虚拟网卡。 Postgresql审计工具 参考 http://www.postgres.cn/news/viewone/1/309 二进制安装 依赖 apt-get install -y --no-install-recommends apt install -y make gcc apt install -y make apt install -y postgresql-server-dev-14 apt install -y libkrb5-dev 下载安装 # 下载源码 https://github.com/pgaudit/pgaudit/tree/1.6.2 make install USE_PGXS=1 配置文件中配置 vim /var/lib/postgresql/data/postgresql.conf shared_preload_libraries=pgaudit docker方式 docker方式 docker run --name dy-pgsql -d -e POSTGRES_PASSWORD=duyong harbor.sxidc.com/yfhub/postgres/audit docker-compose version: '3.1' services: postgres: container_name: duyong_postgres image: harbor.sxidc.com/yfhub/postgres/audit restart: always environment: POSTGRES_USER: root POSTGRES_PASSWORD: root POSTGRES_DB: duyong ports: - 5432:5432 volumes: - ./data:/var/lib/postgresql/data pgadmin4: container_name: duyong_pgadmin4 image: dpage/pgadmin4 restart: always environment: PGADMIN_DEFAULT_EMAIL: admin@fskj.com PGADMIN_DEFAULT_PASSWORD: 123 ports: - 18080:80 配置 # 进入容器 docker exec -it duyong_postgres bash # 开启 psql -d duyong; create extension pgaudit; set pgaudit.log = 'all, -misc'; 测试 # 容器内执行 select name,setting from pg_settings where name like 'pgaudit%'; name | setting ----------------------------+------------ pgaudit.log | all, -misc pgaudit.log_catalog | on pgaudit.log_client | off pgaudit.log_level | log pgaudit.log_parameter | off pgaudit.log_relation | off pgaudit.log_rows | off pgaudit.log_statement | on pgaudit.log_statement_once | off pgaudit.role | (10 rows) 格式配置 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"software/cadence思想.html":{"url":"software/cadence思想.html","title":"cadence官方文档翻译","keywords":"","body":"思想 Cadence是一种开发分布式应用程序的新方法。 它借用了工作流自动化领域的核心术语。所以它的概念包括工作流和活动。工作流可以对事件做出反应，并通过查询返回内部状态。 部署拓扑解释了如何将所有这些概念映射到可部署的软件组件。 无关错误的有状态工作流代码 概览 Cadence核心抽象是一个无错误的有状态工作流。工作流代码的状态(包括它创建的局部变量和线程)不受流程和Cadence服务失败的影响。这是一个非常强大的概念，因为它封装了状态、处理线程、持久计时器和事件处理程序。 例子 让我们来看一个用例。客户注册一个有试用期的应用程序。在此期间之后，如果客户没有取消，他应该被收取每月一次的续费。客户必须通过电子邮件收到有关收费的通知，并且应该能够在任何时候取消订阅。 这个用例的业务逻辑不是很复杂，可以用几十行代码来表示。但是任何实际实现都必须确保业务流程是容错和可伸缩的。有各种方法来设计这样一个系统。 一种方法是以数据库为中心。应用程序流程将定期扫描处于特定状态的客户的数据库表，执行必要的操作，并更新状态以反映这一点。虽然可行，但这种方法有各种缺点。最明显的是，客户状态的状态机很快变得极其复杂。例如，刷卡或发送电子邮件可能会由于下游系统不可用而失败。失败的调用可能需要长时间重试，理想情况下使用指数重试策略。应该对这些调用进行限制，以避免外部系统超载。应该支持“毒丸”，以避免在由于任何原因无法处理单个客户记录时阻塞整个过程。基于数据库的方法通常也存在性能问题。对于需要对处于特定状态的记录进行持续轮询的场景，数据库并不有效。 另一种常用的方法是使用计时器服务和队列。任何更新都会被推送到队列中，然后从队列中消费的worker会更新数据库，并可能在下游队列中推送更多的消息。对于需要调度的操作，可以使用外部定时器服务。这种方法通常可伸缩性要好得多，因为数据库不需要经常轮询更改。但它使编程模型更加复杂，也更容易出错，因为队列系统和数据库之间通常不存在事务更新。 使用Cadence，整个逻辑可以封装在一个简单的持久函数中，该函数直接实现业务逻辑。因为函数是有状态的，所以实现者不需要使用任何额外的系统来确保持久性和容错性。 学习Cadence的开发人员经常会问的问题是“我如何处理工作流工作者过程失败/在我的工作流中重新启动”?答案是你不需要。工作流代码完全不受任何工作人员的故障和停机，甚至不受Cadence服务本身的影响。一旦它们被恢复，工作流需要处理一些事件，比如计时器或活动完成，工作流的当前状态就会完全恢复，继续执行。工作流失败的唯一原因是工作流业务代码抛出异常，而不是底层基础设施中断。 另一个经常被问到的问题是，一个worker是否能够处理比其缓存大小或支持的线程数量更多的工作流实例。答案是，当工作流处于阻塞状态时，可以安全地从worker中移除。之后，当需要(以外部事件的形式)出现时，它可以在不同的或相同的工作者身上复活。因此，假设一个worker可以处理数百万个开放工作流的执行，前提是它可以处理更新速度。 状态恢复和决定论 工作流状态恢复利用了事件来源，这对代码的编写方式有一些限制。主要的限制是工作流代码必须是确定性的，这意味着如果多次执行，它必须产生完全相同的结果。这就排除了工作流代码中的任何外部API调用，因为外部调用可能间歇性地失败或随时改变其输出。这就是为什么所有与外部世界的交流都应该通过活动进行。出于同样的原因，工作流代码必须使用Cadence api来获取当前时间、睡眠和创建新线程。 标识唯一性 工作流ID是由客户端在启动工作流时分配的。它通常是一个业务级ID，如客户ID或订单ID Cadence保证在任何时候每个域只有一个给定ID打开的工作流(跨所有工作流类型)。使用相同ID启动工作流的尝试将会失败，并出现WorkflowExecutionAlreadyStarted错误。 如果有一个相同ID的完整工作流依赖于WorkflowIdReusePolicy选项，则尝试启动一个工作流: AllowDuplicateFailedOnly意味着只有在之前执行的具有相同ID的工作流失败时才允许启动工作流。 AllowDuplicate意味着允许它独立于之前的工作流完成状态启动。 RejectDuplicate意味着根本不允许使用相同的工作流ID启动工作流执行。 TerminateIfRunning意味着终止当前运行的工作流(如果存在的话)，并启动一个新的工作流。 默认为AllowDuplicateFailedOnly。 为了区分同一个工作流ID的多个运行，Cadence用两个ID来标识一个工作流:工作流ID和运行ID。运行ID为服务分配的UUID。准确地说，任何工作流都是由一个三元组唯一标识的:域名、工作流ID和运行ID。 子工作流 一个工作流可以以子工作流:workflow:workflows:的形式执行其他工作流。子工作流完成或失败将报告给父工作流。 使用子工作流的一些原因是: 子工作流可以由一组不包含父工作流代码的独立工作者托管。因此，它将作为一个独立的服务，可以从多个其他工作流调用。 单个工作流的大小是有限的。例如，它不能执行100k活动。子工作流可以用来将问题划分为更小的块。一个父节点(每个子节点执行1000个活动)将执行100万个活动。 子工作流可以使用它的ID来管理某些资源，以保证惟一性。例如，管理主机升级的工作流可以在每个主机上有一个子工作流(主机名就是工作流ID)，并使用它们来确保主机上的所有操作都是序列化的。 子工作流可以用于执行一些周期性逻辑，而不需要扩大父工作流的历史大小。当父进程启动子进程时，它会执行周期性的逻辑调用，需要多少次就执行多少次，然后完成。从父视图来看，它只是一个子工作流调用。 与在单个工作流中配置所有应用程序逻辑相比，子工作流的主要限制是缺乏共享状态。父节点和子节点只能通过异步信号进行通信。但如果它们之间存在紧密耦合，那么使用单个工作流并仅依赖于共享对象状态可能会更简单。 如果您的问题在执行活动和处理信号的数量方面有限制，我们建议从单个工作流实现开始。它比多个异步通信工作流更直接。 工作流重试 工作流代码不受基础架构级别停机和故障的影响。但是它仍然可能由于业务逻辑级别的故障而失败。例如，活动可能会由于超出重试间隔而失败，并且错误没有由应用程序代码处理，或者工作流代码有错误。 有些工作流需要保证它们即使在出现此类故障时也能继续运行。为了支持这样的用例，可以在启动工作流时指定一个可选的指数重试策略。指定该参数后，工作流故障将在计算的重试间隔后从起点重新启动工作流。重试策略参数如下: InitialInterval是第一次重试前的延迟时间 BackoffCoefficient。重试策略是指数级的。系数指定重试间隔的增长速度。系数1表示重试间隔总是等于InitialInterval。 MaximumInterval指定重试的最大间隔时间。适用于大于1的系数。 MaximumAttempts指定在出现故障时尝试执行工作流的次数。如果超过此限制，则工作流将失败，无需重试。如果指定了ExpirationInterval，则不需要 ExpirationInterval指定在出现故障时尝试执行工作流的时间。如果超过此时间间隔，则工作流将失败，无需重试。如果指定了MaximumAttempts，则不需要。 NonRetryableErrorReasons允许指定不应重试的错误。例如，重试无效参数error在某些情况下没有意义。 活动 无故障状态工作流代码是Cadence的核心抽象。但是，由于确定性的执行需求，它们不允许直接调用任何外部API。相反，它们编排活动的执行。在其最简单的形式中，Cadence活动是受支持语言中的一个函数或对象方法。Cadence不会在失败的情况下恢复活动状态。因此，活动函数可以不受限制地包含任何代码。 活动通过任务列表异步调用。任务列表本质上是一个用于存储活动任务的队列，直到它被可用的工作者拾取。工作者通过调用活动的实现函数来处理活动。当函数返回时，worker将结果报告给Cadence服务，Cadence服务将通知工作流完成。通过从不同的流程完成一个活动，完全异步地实现它是可能的。 超时设定 Cadence对活动持续时间没有任何系统限制。由应用程序选择执行的超时。这些是可配置的活动超时: ScheduleToStart是从工作流请求活动执行到工作者开始执行的最长时间。触发这种超时的通常原因是所有工作人员处于停机状态或无法跟上请求速率。我们建议将此超时设置为在所有可能的worker中断情况下工作流愿意等待活动执行的最大时间。 StartToClose是一个活动被工作者选中后可以执行的最大时间。 ScheduleToClose是工作流请求活动执行到完成的最大时间 Heartbeat是心跳请求之间的最大时间间隔。参见长时间运行活动。 重试 由于Cadence不能恢复活动的状态，并且它们可以与任何外部系统通信，因此故障是可以预见的。因此，Cadence支持自动活动重试。任何活动在被调用时都可以有一个关联的重试策略。重试策略参数如下: InitialInterval是第一次重试前的延迟时间。 BackoffCoefficient。重试策略是指数级的。系数指定重试间隔的增长速度。系数1表示重试间隔总是等于InitialInterval。 MaximumInterval指定重试的最大间隔时间。适用于大于1的系数。 MaximumAttempts指定在出现故障时尝试执行某个活动的次数。如果超出此限制，则将错误返回到调用该活动的工作流。如果指定了ExpirationInterval，则不需要。 ExpirationInterval指定在出现故障时尝试执行活动的时间。如果超出此间隔，则将错误返回到调用该活动的工作流。如果指定了MaximumAttempts，则不需要。 NonRetryableErrorReasons允许你指定不应该重试的错误。例如，重试无效参数error在某些情况下没有意义。 在某些情况下，失败时不应该重试单个活动，而应该重试整个工作流。例如，媒体编码工作流将文件下载到主机，对其进行处理，然后将结果上传到存储。在这个工作流中，如果承载工作者的主机死亡，所有三个活动都应该在另一个主机上重试。这样的重试应该由工作流代码处理，因为它们非常特定于用例。 长时间运行的活动 对于长时间运行的活动，我们建议您指定相对较短的心跳超时和持续的心跳。通过这种方式，即使是运行时间很长的活动的worker故障也可以及时处理。指定心跳超时的活动将从其实现中周期性地调用heartbeat方法。 心跳检测请求可以包括特定于应用程序的有效负载。这对于保存活动执行进度非常有用。如果一个活动由于错过心跳而超时，下一次执行它的尝试可以访问该进程并从该点继续执行。 长时间的活动可以作为领导人选举的一个特例。节奏超时使用第二分辨率。因此，它不是实时应用程序的解决方案。但是如果可以在几秒钟内对流程失败做出反应，那么Cadence心跳活动是一个很好的选择。 这种领导人选举的一个常见用例是监控。活动执行一个内部循环，周期性地轮询一些API并检查一些条件。它也在每一次迭代中跳动。如果条件满足，活动就完成，让它的工作流来处理它。如果活动工作器死亡，则该活动在超过心跳间隔后超时，并在另一个工作器上重试。同样的模式也适用于在Amazon S3桶中轮询新文件或REST或其他同步api中的响应。 撤销 工作流可以请求取消活动。目前，一项活动被取消的唯一方式就是心跳。心跳请求失败，出现一个特殊错误，指示活动已取消。然后由活动实现执行所有必要的清理工作，并报告它已经完成了。由工作流实现来决定是要等待活动取消确认，还是直接进行而不等待。 活动心跳故障的另一种常见情况是，调用它的工作流处于完成状态。在这种情况下，一个活动也会执行清理。 活动任务路由通过任务列表 活动通过任务列表分配给工人。任务列表是工作人员监听的队列。任务列表是高度动态和轻量级的。它们不需要显式地注册。每个工作进程有一个任务列表是可以的。通过单个任务列表调用多个活动类型是正常的。在某些情况下(如主机路由)，在多个任务列表中调用相同的活动类型是很正常的。 以下是在一个工作流中使用多个活动任务列表的一些用例: 流控制。从任务列表中使用的工作者只有在有可用容量时才会请求活动任务。因此，员工永远不会因为需求激增而超载。如果请求活动执行的速度比工作人员处理它们的速度快，那么它们就会积压在任务列表中。 节流。每个活动工作者可以指定允许处理任务列表上活动的最大速率。即使它有空闲容量，也不会超过这个限制。它还支持全局任务列表速率限制。这个限制适用于给定任务列表的所有工作者。它经常用于限制活动调用的下游服务的负载。 独立部署一组活动。考虑一个承载活动的服务，它可以独立于其他活动和工作流进行部署。要将活动任务发送到此服务，需要一个单独的任务列表。 不同能力的工人。例如，GPU盒子上的工作人员vs非GPU盒子。在这种情况下，拥有两个独立的任务列表允许工作流选择向哪个任务发送执行请求。 将活动路由到特定的主机。例如，在媒体编码的情况下，转换和上传活动必须在与下载活动相同的主机上运行。 将活动路由到特定流程。例如，一些活动加载大型数据集并将其缓存到流程中。应该将依赖于此数据集的活动路由到相同的流程。 多个优先级。每个优先级有一个任务列表，每个优先级有一个工作池。 版本控制。一个新的向后不兼容的活动实现可能使用不同的任务列表。 异步活动完成 默认情况下，活动是一个函数或方法，这取决于客户端库语言。一旦函数返回，一个活动就完成了。但在某些情况下，活动实现是异步的。例如，它通过消息队列转发到外部系统。回复来自另一个队列。 为了支持这样的用例，Cadence允许在活动功能完成时不完成的活动实现。在这种情况下，应该使用一个单独的API来完成活动。这个API可以从任何进程调用，甚至可以用原始活动工作者使用的不同编程语言调用。 本地活动 有些活动寿命很短，不需要队列语义、流控制、速率限制和路由功能。因此，Cadence支持所谓的本地活动特性。本地活动与调用它们的工作流在同一个工作流程中执行。 你将通过使用当地的活动来权衡什么 较少的可调试性:没有ActivityTaskScheduled和ActivityTaskStarted事件。所以你无法看到输入。 没有任务列表分派:工作者总是与工作流决策工作者相同。你没有选择使用活动工作者的权利。 重复执行的可能性更大。虽然在使用重试策略时常规活动也可以执行多次，但局部活动发生的机会更大。因为本地活动结果直到DecisionTaskCompleted才被记录到历史记录中。此外，当在一行中执行多个本地活动时，SDK(Java+Golang)将优化记录，只按间隔记录(在当前决策任务超时之前)。 没有记录心跳的长时间运行能力 没有Tasklist全局速率限制 考虑为以下函数使用本地活动: 幂等函数 不超过几秒钟 不需要全球速率限制 不需要路由到特定的工人或工人池 可以与调用它们的工作流在相同的二进制文件中实现吗 非业务关键，因此失去一些可调试性是可以接受的(例如。日志记录、加载配置) 当你真的需要优化的时候。例如，如果有许多计时器同时启动来调用活动，它可能会使Cadence的服务器过载。使用本地活动可以帮助节省服务器容量。 本地活动的主要好处是，与通常的活动调用相比，它们更有效地利用了Cadence服务资源，并且具有更低的延迟开销。 事件处理 可以用外部事件来通知无错误的有状态工作流。信号总是指向特定工作流实例的点对点。信号总是按照接收到信号的顺序进行处理。 信号在很多情况下都是有用的。 事件聚合与关联 Cadence并不是通用流处理引擎(如Apache Flink或Apache Spark)的替代品。但在某些情况下，它更适合。例如，当所有应该聚合和关联的事件总是应用于某个具有明确ID的业务实体时。然后，当满足某个条件时，就应该执行动作。 主要的限制是单个Cadence工作流的吞吐量非常有限，而工作流的数量实际上是无限的。因此，如果您需要聚合每个客户的事件，而您的应用程序有1亿个客户，并且每个客户每秒生成的事件不超过20个，那么Cadence就可以很好地工作。但是，如果您想为美国客户聚合所有事件，那么这些事件的发生率将超出单个工作流的能力。 例如，物联网设备产生事件，按照一定的事件顺序，设备需要重新provision。将为每个设备创建一个工作流实例，每个实例将管理设备的状态机，并在必要时执行重新供应活动。 另一个用例是客户忠诚度计划。每当客户进行购买时，Apache Kafka会生成一个事件供下游系统处理。一个忠诚服务Kafka消费者接收事件，并使用Cadence signalWorkflowExecution API向客户发送购买的信号。该工作流程累积购买的数量。如果达到了指定的阈值，则工作流执行一个活动，该活动通知一些外部服务，客户已达到忠诚度计划的下一个级别。工作流还执行活动，定期发送消息 人工任务 许多业务流程都涉及到人工参与者。实现外部交互的标准Cadence模式是在外部系统中执行创建人工任务的活动。它可以是带有表单的电子邮件，或某个外部数据库中的记录，或移动应用程序通知。当用户改变任务状态时，会向相应的工作流发送一个信号。例如，当表单被提交，或者移动应用程序通知被确认时。有些任务有多种可能的操作，如索赔、返回、完成、拒绝。所以可以发送与之相关的多个信号。 流程执行变更 如果发生了一些外部事件，某些业务流程应该更改其行为。例如，在执行订单发货工作流时，项目数量的任何更改都可以以信号的形式交付。 另一个例子是服务部署工作流。在向Kubernetes集群推出新软件版本时，发现了一些问题。在研究问题时，可以使用一个信号要求工作流暂停。然后可以使用继续或回滚信号来执行适当的操作。 同步 Cadence工作流是非常一致的，所以它们可以用作执行动作的同步点。例如，一个用户的所有消息都需要按顺序处理，但是底层消息传递基础结构可以并行交付它们。Cadence解决方案将为每个用户提供一个工作流，并在接收到事件时发出信号。然后，工作流将在内部数据结构中缓冲所有信号，然后为接收到的每一个信号调用一个活动 同步查询 工作流代码是有状态的，Cadence框架可以在各种软件和硬件故障时保留它。在工作流执行期间，状态会不断变化。为了向外部世界公开这个内部状态，Cadence提供了同步查询功能。从工作流实现者的角度来看，查询公开为由外部实体调用的同步回调。可以为每个工作流类型提供多个这样的回调，向不同的外部系统公开不同的信息。 要执行查询，外部客户端调用同步Cadence API，提供域、workflowID、查询名称和可选查询参数。 查询回调必须是只读的，不能以任何方式改变工作流状态。另一个限制是查询回调不能包含任何阻塞代码。以上两个限制都排除了从查询处理程序调用活动的能力。 Cadence团队目前正致力于实现更新功能，该功能在调用方式上与查询类似，但将支持工作流状态变化和本地活动调用。从用户的角度来看，更新类似于信号+强一致性查询，但在Cadence中以更便宜的方式实现。 堆栈跟踪查询 Cadence客户端库公开了一些开箱即用的预定义查询。目前唯一支持的内置查询是stack_trace。此查询返回所有工作流拥有的线程的堆栈。这是一种在生产中排除任何工作流故障的好方法。 部署拓扑 概述 Cadence是一个高度可扩展的无错误状态代码平台。对错误无关的代码是实现容错和持久性的常用技术的下一个抽象级别。 一个常见的基于Cadence的应用程序由一个Cadence服务、工作流和活动工作者以及外部客户端组成。请注意，这两种类型的工作者以及外部客户端都是角色，如果需要，可以在单个应用程序流程中进行配置。 Cadence的核心是一个高度可扩展的多业务服务。该服务通过强类型gRPC API(打开新窗口)公开其所有功能。一个Cadence集群包含多个服务，每个服务可以运行在多个节点上，以提高可扩展性和可靠性: 前端:这是一个无状态的服务，用于处理来自Workers的传入请求。期望使用外部负载均衡机制在前端实例之间分配负载。 历史服务:在其中实现编排工作流步骤和活动的核心逻辑 匹配服务:将需要执行的工作流/活动任务匹配到能够执行它们的工作流/活动工作者。匹配的任务由历史服务分配执行 内部工作者服务:实现Cadence工作流程和活动以满足内部需求，比如存档 工作者:实际上是Cadence的客户端应用。这是执行用户创建的工作流和活动逻辑的地方 在内部，它依赖于持久存储。目前，Apache Cassandra, MySQL, PostgreSQL, CockroachDB (PostgreSQL兼容(打开新窗))和TiDB (MySQL兼容(打开新窗))存储支持开箱即用。对于使用复杂谓词列出工作流，可以使用ElasticSearch和OpenSearch集群。 Cadence服务负责保持工作流状态和相关的持久计时器。它维护内部队列(称为任务列表)，用于将任务分发给外部工作者。 Cadence服务具有多业务特性。因此，我们期望实现不同用例的多个worker池连接到相同的服务实例。例如，在Uber，一项服务被超过100个应用程序使用。与此同时，一些外部客户为每个应用程序部署一个Cadence服务实例。对于本地开发，使用docker-compose配置的本地Cadence服务实例。 工作流工作者 Cadence重用了工作流自动化领域的术语。因此，无关错误的有状态代码被称为工作流。 Cadence服务不会直接执行工作流代码。工作流代码由外部(从服务的角度)工作流工作者程序托管。这些工作者程序从Cadence服务接收决策任务，这些决策任务包含工作流预期要处理的事件，将它们交付给工作流代码，并将工作流决策传递回服务 由于工作流代码是服务的外部，所以它可以用任何语言来实现，这些语言可以与服务Thrift API对话。目前Java和Go客户端已经可以生产了。而Python和c#客户端还在开发中。如果您有兴趣用您喜欢的语言提供客户端，请告诉我们。 Cadence服务API没有强制使用任何特定的工作流定义语言。因此，可以实现一个特定的worker来执行任何现有的工作流规范。Cadence团队选择的开箱即用的模型是基于持久功能的理念。持久函数尽可能地接近应用程序业务逻辑，所需的管道很少。 活动工作者 无关错误的工作流代码不受基础设施故障的影响。 但它必须与不完美的外部世界沟通，在那里失败是常见的。所有与外部世界的交流都是通过活动完成的。活动是可以执行任何特定于应用程序的操作的代码片段，比如调用服务、更新数据库记录或从Amazon S3下载文件。与排队系统相比，Cadence活动的功能非常丰富。示例特性包括任务路由到特定进程、无限重试、心跳和无限执行时间。 活动由活动工作者程序托管，这些程序从Cadence服务接收活动任务，调用相应的活动实现并报告任务完成状态 外部客户 工作流和活动工作者托管工作流和活动代码。但是要创建一个工作流实例(Cadence术语中的执行)，应该使用StartWorkflowExecution Cadence服务API调用。通常，工作流是由外部实体(如ui、微服务或cli)启动的。 这些实体还可以: 以信号的形式通知工作流异步外部事件 同步查询工作流状态 同步地等待工作流的完成 取消、终止、重启和重置工作流 使用列表API搜索特定的工作流 任务列表 当工作流调用一个活动时，它将ScheduleActivityTask决策发送给Cadence服务。因此，服务更新工作流状态，并将一个活动任务分派给实现该活动的工作者。不是直接调用工作者，而是使用一个中间队列。因此，服务将一个活动任务添加到这个队列中，然后工人使用一个长轮询请求接收该任务。Cadence将这个用于分派活动任务的队列称为活动任务列表。 类似地，当工作流需要处理外部事件时，将创建决策任务。决策任务列表用于将其交付给工作流工作者(也称为决策者)。 虽然Cadence任务列表是队列，但它们与常用的队列技术有一些不同。主要的一点是它们不需要显式注册，而是按需创建。任务列表的数量不受限制。一个常见的用例是每个辅助流程都有一个任务列表，并使用它向流程交付活动任务。另一个用例是每个工作池都有一个任务列表。 使用任务列表来交付任务，而不是通过同步RPC调用活动工作者有多个优点: Worker不需要任何开放端口，这更安全 Worker不需要通过DNS或任何其他网络发现机制发布自己。 当所有workers都停止工作时，消息被持久化到任务列表中，等待workers恢复。 Worker只有在有空闲容量时才会查询消息，这样就不会出现过载。、 在大量工作者之间实现自动负载平衡。 任务列表支持服务器端节流。这允许您将任务分派率限制到工作者池中，并且仍然支持在出现峰值时以更高的速率添加任务。 任务列表可以用来将请求路由到特定的工作者池，甚至特定的进程。 归档 存档是一种功能，可以自动将工作流历史记录(历史存档)和可见性记录(可见性存档)在保留期后从持久性转移到二级数据存储，从而允许用户保持工作流历史记录和可见性记录，只要有必要，而不会压倒Cadence主要数据存储。有两个原因，你可以考虑打开你的域名存档: 合规性:由于法律原因，历史记录可能需要长时间存储。 调试:在调试时仍然可以访问旧的历史记录 目前对archive特性的实现有两个限制: 需要RunID:为了检索归档的工作流历史，需要同时使用workflowID和RunID。 尽最大努力:历史记录或可见性记录可能从Cadence主持久性中删除，而没有首先进行归档。这些案例很罕见，但以目前的档案状态是可能的。请查看FAQ部分，了解发生这种情况时如何得到通知。 概念 Archiver: Archiver是负责归档和检索工作流历史和可见性记录的组件。它的接口是通用的，并支持不同类型的归档位置:本地文件系统，S3, Kafka等。如果您想为您的数据存储添加一个新的归档器实现，请检查这个README(打开新窗口)。 URI: URI用于指定归档位置。根据URI的方案部分，系统将选择相应的归档程序来执行归档操作。 配置归档 档案由域级配置和集群级配置控制。历史记录和可见性归档具有独立的域/集群配置，但它们具有相同的目的。 集群级别归档配置 Cadence集群可以处于以下三种归档状态之一: 禁用:将不会发生存档，存档程序在服务启动时不会初始化。 暂停:该状态尚未实现。当前将集群设置为暂停与将其设置为禁用相同。 启用:存档将发生。 启用归档集群意味着将归档工作流历史记录。还有另一个配置控制是否可以访问存档的历史记录或可见性记录。这两个配置都在静态yaml中定义了默认值，可以通过动态配置重写。但是请注意，只有在静态yaml中启用归档时，动态配置才会生效。 域级别归档配置 一个域包括两个与档案相关的配置: 状态:启用或禁用。如果某个域处于禁用状态，则不会对该域进行存档。 URI:存档历史记录或可见性记录的方案和位置。当域第一次启用存档时，将设置URI，并且永远不能更改。如果在首次启用存档域时未指定URI，则将使用静态配置中的默认URI。 本地运行 您可以按照以下步骤在本地运行和测试存档特性: ./cadence-server start ./cadence --do samples-domain domain register --gd false --history_archival_status enabled --visibility_archival_status enabled --retention 0 Run the helloworld cadence-sample (opens new window)by following the README 从日志输出中复制完成的工作流id 通过归档的可见性记录检索runID ./cadence --do samples-domain wf listarchived -q 'WorkflowID = \"\"' 检索历史存档 ./cadence --do samples-domain wf show --wid --rid 在步骤2中，我们注册了一个新域，并为该域启用了历史记录和可见性存档特性。由于我们在注册新域时没有提供归档URI，因此在config/development中指定了默认URI。使用yaml。默认URI为:file:///tmp/cadence_archival/development(历史存档)，file:///tmp/cadence_vis_archival/development(可见存档)。您可以在/tmp/cadence_archival/development目录下找到归档的工作流历史记录，在/tmp/cadence_vis_archival/development目录下找到归档的可见性记录。 生产运行 Cadence支持将工作流历史记录上传到谷歌Cloud和Amazon S3，以便在生产中存档。检查GCloud归档组件(打开新窗)和S3归档组件(打开新窗)中的文档。 Below is an example of Amazon S3 archival configuration: archival: history: status: \"enabled\" enableRead: true provider: s3store: region: \"us-east-2\" visibility: status: \"enabled\" enableRead: true provider: s3store: region: \"us-east-2\" domainDefaults: archival: history: status: \"enabled\" URI: \"s3://dev-cad\" visibility: status: \"enabled\" URI: \"s3://dev-cad\" FAQ 什么时候存档? 理论上，我们希望在工作流关闭和保留期过去后，历史和可见性存档都发生。然而，由于实现中的一些限制，只有历史存档在保留期之后发生，而可见性存档在工作流关闭后立即发生。请将此视为Cadence内部的实现细节，不要依赖于此事实。存档的数据只应在保留期后进行检查，未来我们可能会改变我们做可见性存档的方式。 可见性存档的查询语法是什么? listArchived CLI命令和API接受一个类似sql的查询来检索存档的可见性记录，类似于listWorkflow命令的工作方式。不幸的是，由于不同的Archiver实现具有非常不同的功能，目前还没有适用于所有Archiver实现的通用查询语法。请检查您的域使用的Archiver的README(例如，S3(打开新窗)和GCP(打开新窗))，以了解支持的查询语法和限制。 档案如何与全局域交互? 如果您有一个全局域，当存档发生时，它将首先在活动集群上运行，一段时间后，当复制发生时，它将在备用集群上运行。对于历史存档，Cadence将检查是否已执行上传操作，并跳过重复操作。而能见度档案则没有这种检查，会上传重复的能见度记录。根据Archiver实现的不同，那些重复的上传可能会占用底层存储中的更多空间，并且可能会返回重复的条目。 我可以指定多个归档uri吗? 每个域只能有一个用于历史存档的URI和一个用于可见性存档的URI。但是，不同的域可以有不同的uri(采用不同的方案)。 档案如何与PII一起工作? 任何节拍工作流都不应该在明文PII上操作。Cadence可以被认为是一个数据库，就像我们不会在数据库中存储PII一样，PII不应该存储在Cadence中。当启用归档时，这一点更加重要，因为这些历史记录可以永远保存。 未来的工作计划 支持检索归档的工作流历史记录，而不提供runID。 确保归档之前没有从主持久性删除历史记录或可见性记录。 实现暂停状态。在这种状态下，不会发生档案，但历史或可见性记录也不会从持久性中删除。一旦从暂停状态再次启用，将发生所有跳过的存档。 Cross-DC复制 在发生数据中心故障转移时，Cadence Global Domain特性为客户端提供了从另一个集群继续执行工作流的能力。尽管可以将全局域配置为复制到任意数量的集群，但它只在单个集群中被认为是活动的。 全局域体系结构 Cadence引入了一个新的顶级实体Global Domains，它为跨集群复制工作流执行提供支持。可以使用多个集群配置全局域，但在任何时候只能在其中一个集群中处于活动状态。当在其他集群中没有活动时，我们称之为被动或备用。 如果一个全局域只配置在一个集群上，备用集群的数量可以为零。这是首选/推荐。 全局域的任何工作流只能在其活动集群中进行。工作流进程复制到其他备用集群。例如，通过调用StartWorkflow启动工作流，或通过PollForActivityTask API启动活动，只能在其活动集群中处理。活动集群取得进展后，备用集群(如果有的话)将从活动集群轮询历史，以复制工作流状态 然而，备用集群也可以接收请求，例如启动工作流或启动活动。它们知道域在哪个集群中活动。因此，请求可以路由到活动集群。这在Cadence中被称为api转发。api转发使得故障转移期间没有停机成为可能。api-forwarding策略有两种:selected-api-forwarding策略和all-domain-api-forwarding策略。 当使用selected-api转发时，应用程序需要在每个集群上运行一组不同的活动和工作流工作者轮询。Cadence只会在当前的活动集群上分派任务;备用集群上的工作人员将处于空闲状态，直到全局域故障转移完成。如果XDC在运行在非常远程的数据中心(区域)中的多个集群中使用，那么建议这样做，因为这样做的转发成本很高。 当使用全域api转发时，应用程序只需要在一个集群上运行活动和工作流工作者轮询。这使得应用程序的设置更加容易。当集群都位于本地或附近的数据中心时，建议这样做。详见讨论。 冲突解决 与至多为活动执行提供一次语义的本地域不同，全局域只能支持至少一次语义。Cadence全局域依赖于跨集群的事件异步复制，因此在发生故障转移时，由于复制任务延迟，可能会在新的活动集群上再次分派活动。这还意味着，每当新集群在故障转移后更新工作流执行时，就不能应用该执行的任何以前的复制任务。这将导致在前一个活动集群中工作流执行所取得的一些进展的损失。在这种冲突解决过程中，Cadence在丢弃复制任务之前将任何外部事件(如Signals)重新注入到新的历史记录中。即使在故障转移期间有些进展可能会回滚，Cadence也保证了工作流不会被卡住，并将继续前进。 全局域概念、配置和操作 概念 IsGlobal 此配置用于区分集群的本地域和全局域。它控制更新时复制任务的创建，允许跨集群复制状态。这是一个只读设置，只能在提供域时设置。 Clusters 域可以故障转移到的集群列表，包括当前活动的集群。这也是一个只读设置，只能在提供域时设置。路线图上的重新复制特性将允许更新此配置，以便在将来添加/删除集群。 Active Cluster Name 全局域当前主集群的名称。每次全局域故障转移到另一个集群时都会更新此配置。 Failover Version 唯一的故障转移版本，它还表示全局域的当前活动集群。Cadence允许从任何集群触发故障转移，因此故障转移版本被设计成不允许在两个集群上错误地同时触发故障转移时发生冲突。 通过CLI运作 Cadence CLI还可以用于查询域配置或执行故障切换。下面是一些有用的命令。 描述全局域 可以使用以下命令描述全局域元数据: $ cadence --do cadence-canary-xdc d desc Name: cadence-canary-xdc Description: cadence canary cross dc testing domain OwnerEmail: cadence-dev@cadenceworkflow.io DomainData: Status: REGISTERED RetentionInDays: 7 EmitMetrics: true ActiveClusterName: dc1 Clusters: dc1, dc2 本地运行 最好的方法是使用Cadence docker-compose(打开新窗口):docker-compose -f docker-compose-multiclusters。yml起来 生产运行 启用全局域特性需要在静态配置中启用。 这里我们以clusterDCA和clusterDCB为例。我们选择clusterDCA作为主(通常称为“主”)集群。作为主集群的唯一区别是它负责域名注册。主节点可以稍后更改，但需要在所有集群中保持相同。 clusterDCA的ClusterMeta配置应该是 dcRedirectionPolicy: policy: \"selected-apis-forwarding\" clusterMetadata: enableGlobalDomain: true failoverVersionIncrement: 10 masterClusterName: \"clusterDCA\" currentClusterName: \"clusterDCA\" clusterInformation: clusterDCA: enabled: true initialFailoverVersion: 1 rpcName: \"cadence-frontend\" rpcAddress: \"<>:<>\" clusterDCB: enabled: true initialFailoverVersion: 0 rpcName: \"cadence-frontend\" rpcAddress: \"<>:<>\" clusterDCB的ClusterMeta配置应该是 dcRedirectionPolicy: policy: \"selected-apis-forwarding\" clusterMetadata: enableGlobalDomain: true failoverVersionIncrement: 10 masterClusterName: \"clusterDCA\" currentClusterName: \"clusterDCB\" clusterInformation: clusterDCA: enabled: true initialFailoverVersion: 1 rpcName: \"cadence-frontend\" rpcAddress: \"<>:<>\" clusterDCB: enabled: true initialFailoverVersion: 0 rpcName: \"cadence-frontend\" rpcAddress: \"<>:<>\" 部署完成后: Register a global domain cadence --do domain register --global_domain true --clusters clusterDCA clusterDCB --active_cluster clusterDCA Run some workflow and failover domain from one to another cadence --do domain update --active_cluster clusterDCB 然后，应该将域故障转移到clusterDCB。现在工作流在clusterDCA中是只读的。因此，从clusterDCA轮询任务的工作人员将变得空闲。 注1:即使clusterDCA对于这个域是备用/只读的，它对于另一个域也可以是活动的。所以活动/备用是基于每个域而不是每个集群。换句话说，例如，如果在clusterDCA的DC故障的情况下使用XDC，则需要将所有域从clusterDCA故障转移到clusterDCB。 注2:即使一个域在集群中是备用/只读的，比如clusterDCA，发送写请求(startWF, signalWF等)仍然可以工作，因为在Frontend服务中有一个转发组件。它将尝试将请求重新路由到该域的活动集群。 搜索工作流(先进的可见性) 介绍 Cadence支持使用定制的键值对创建工作流，更新工作流代码中的信息，然后使用类似sql的查询列出/搜索工作流。例如，您可以创建带有key city和age的工作流，然后使用city = seattle和age > 22搜索所有工作流。 还要注意，正常的工作流属性，如开始时间和工作流类型，也可以查询。例如，当从CLI或使用列表api (Go(打开新窗)，Java(打开新窗))列出工作流时，可以指定以下查询: WorkflowType = \"main.Workflow\" AND CloseStatus != \"completed\" AND (StartTime > \"2019-06-07T16:46:34-08:00\" OR CloseTime > \"2019-06-07T16:46:34-08:00\") ORDER BY StartTime DESC 在其他地方，这也被称为高级能见度。而基本的可见性是指基本的清单，不能够搜索。 备忘录vs搜索属性 Cadence提供了两种方法来创建具有键-值对的工作流:备忘录和搜索属性。备忘录只能在工作流程开始时提供。此外，备忘录数据没有索引，因此无法搜索。当使用列表api列出工作流时，Memo数据是可见的。搜索属性数据被索引，因此您可以通过查询这些属性来搜索工作流。但是，搜索属性需要使用Elasticsearch。 备忘录和搜索属性在StartWorkflowOptions(打开新窗口)的Go客户端中可用。 type StartWorkflowOptions struct { // ... // Memo - Optional non-indexed info that will be shown in list workflow. Memo map[string]interface{} // SearchAttributes - Optional indexed info that can be used in query of List/Scan/Count workflow APIs (only // supported when Cadence server is using Elasticsearch). The key and value type must be registered on Cadence server side. // Use GetSearchAttributes API to get valid key and corresponding value type. SearchAttributes map[string]interface{} } 搜索属性(Go客户端使用情况) 当使用Cadence Go客户端，提供键值对作为SearchAttributes在StartWorkflowOptions(打开新的窗口)。 SearchAttributes是map[string]interface{}键需要被允许列出，以便Cadence知道属性键的名称和值类型。映射中提供的值必须与注册的值类型相同。 允许列出搜索属性 首先使用CLI查询搜索属性列表 $ cadence --domain samples-domain cl get-search-attr +---------------------+------------+ | KEY | VALUE TYPE | +---------------------+------------+ | CloseStatus | INT | | CloseTime | INT | | CustomBoolField | DOUBLE | | CustomDatetimeField | DATETIME | | CustomDomain | KEYWORD | | CustomDoubleField | BOOL | | CustomIntField | INT | | CustomKeywordField | KEYWORD | | CustomStringField | STRING | | DomainID | KEYWORD | | ExecutionTime | INT | | HistoryLength | INT | | RunID | KEYWORD | | StartTime | INT | | WorkflowID | KEYWORD | | WorkflowType | KEYWORD | +---------------------+------------+ 使用admin CLI添加一个新的搜索属性: cadence --domain samples-domain adm cl asa --search_attr_key NewKey --search_attr_type 1 属性类型的编号映射如下: 0 = String(Text) 1 = Keyword 2 = Int 3 = Double 4 = Bool 5 = DateTime 关键字和字符串(文本) 注1:字符串在ElasticSearch中被重命名为Text(打开新窗口)。Cadence也计划(打开新窗口)重命名它。 注2:关键字和字符串(文本)是从Elasticsearch中获取的概念。String(Text)中的每个单词都被认为是可搜索的关键字。对于UUID，这可能会有问题，因为Elasticsearch将单独索引UUID的每个部分。要将整个字符串视为可搜索的关键字，请使用keyword类型。 例如，值为“2dd29ab7-2dd8-4668-83e0-89cae261cfb1”的键RunID 作为关键字只能通过RunID = \"2dd29ab7-2dd8-4668-83e0-89cae261cfb1\"匹配(或在未来使用正则表达式(打开新窗口)) 作为一个字符串(文本)将被RunID = \"2dd8\"匹配，这可能会导致不需要的匹配 不能在Order By查询中使用字符串(文本)类型。 这里有一些预先允许的搜索属性，便于测试: CustomKeywordField CustomIntField CustomDoubleField CustomBoolField CustomDatetimeField CustomStringField 它们的类型在它们的名称中标明。 值类型 以下是搜索属性值类型及其对应的golang类型: Keyword = string Int = int64 Double = float64 Bool = bool Datetime = time.Time String = string 限制 我们建议通过以下限制来限制Elasticsearch索引的数量: 键数:每个工作流100个 值的大小:每个值2kb 键和值的总大小:每个工作流40kb Cadence保留像DomainID、WorkflowID和RunID这样的键。这些只能用于列表查询。这些值不可更新。 工作流中的Upsert搜索属性 UpsertSearchAttributes(打开新窗口)用于从工作流代码中添加或更新搜索属性。 Go搜索属性的示例可以在github.com/uber-common/cadence-samples(打开新窗口)找到 UpsertSearchAttributes将属性合并到工作流中现有的映射。考虑下面的示例工作流代码: func MyWorkflow(ctx workflow.Context, input string) error { attr1 := map[string]interface{}{ \"CustomIntField\": 1, \"CustomBoolField\": true, } workflow.UpsertSearchAttributes(ctx, attr1) attr2 := map[string]interface{}{ \"CustomIntField\": 2, \"CustomKeywordField\": \"seattle\", } workflow.UpsertSearchAttributes(ctx, attr2) } 在第二次调用UpsertSearchAttributes之后，映射将包含: map[string]interface{}{ \"CustomIntField\": 2, \"CustomBoolField\": true, \"CustomKeywordField\": \"seattle\", } 不支持删除字段。为了达到类似的效果，可以将该字段设置为一个哨兵值。例如，要删除“CustomKeywordField”，请将其更新为“impossibleVal”。然后搜索CustomKeywordField != ' impossibleVal '将匹配CustomKeywordField不等于\"impossibleVal\"的工作流，它包括没有CustomKeywordField设置的工作流。 使用工作流。GetInfo获取当前搜索属性。 ContinueAsNew和Cron 当执行ContinueAsNew或使用Cron时，搜索属性(和备忘录)将在默认情况下转移到新运行。 查询能力 在CLI中列出工作流时，可以使用类似sql的where子句查询工作流，或者使用列表api (Go(打开新窗口)，Java(打开新窗口))。 注意，在查询时，您只能看到来自一个域的工作流。 支持的操作符 AND, OR, () =, !=, >, >=, IN BETWEEN ... AND ORDER BY 默认属性 在新版本中添加了越来越多的默认属性。请使用CLI get-search-attr命令或GetSearchAttributes API获取。一些名称和类型如下: https://cadenceworkflow.io/docs/concepts/search-workflows/#query-capabilities 关于查询的一般注意事项 Pagesize默认为1000，不能大于10k 对Cadence时间戳(StartTime, CloseTime, ExecutionTime)的范围查询不能大于9223372036854775807 (maxInt64 - 1001) 按时间范围查询将有1ms的分辨率 查询列名区分大小写 当检索大量工作流(10M以上)时，ListWorkflow可能需要更长的时间。 要检索大量的工作流而不关心顺序，使用ScanWorkflow API 为了有效地计算工作流的数量，可以使用CountWorkflow API 工具支持 CLI Cadence服务器的0.6.0版本支持搜索属性。您还可以在最新的CLI Docker映像中使用CLI(打开新窗口)(0.6.4或更高版本支持)。 使用搜索属性启动工作流 cadence --do samples-domain workflow start --tl helloWorldGroup --wt main.Workflow --et 60 --dt 10 -i '\"vancexu\"' -search_attr_key 'CustomIntField | CustomKeywordField | CustomStringField | CustomBoolField | CustomDatetimeField' -search_attr_value '5 | keyword1 | vancexu test | true | 2019-06-07T16:16:36-08:00' 使用列表API/命令搜索工作流 cadence --do samples-domain wf list -q '(CustomKeywordField = \"keyword1\" and CustomIntField >= 5) or CustomKeywordField = \"keyword2\"' -psa cadence --do samples-domain wf list -q 'CustomKeywordField in (\"keyword2\", \"keyword1\") and CustomIntField >= 5 and CloseTime between \"2018-06-07T16:16:36-08:00\" and \"2019-06-07T16:46:34-08:00\" order by CustomDatetimeField desc' -psa 要只列出打开的工作流，请在查询的末尾添加CloseTime = missing。 注意，查询可以支持多种类型的过滤器: cadence --do samples-domain wf list -q 'WorkflowType = \"main.Workflow\" and (WorkflowID = \"1645a588-4772-4dab-b276-5f9db108b3a8\" or RunID = \"be66519b-5f09-40cd-b2e8-20e4106244dc\")' cadence --do samples-domain wf list -q 'WorkflowType = \"main.Workflow\" StartTime > \"2019-06-07T16:46:34-08:00\" and CloseTime = missing' 以上所有命令都可以通过ListWorkflowExecutions API完成。 cadence --do samples-domain wf count -q '(CustomKeywordField = \"keyword1\" and CustomIntField >= 5) or CustomKeywordField = \"keyword2\"' cadence --do samples-domain wf count -q 'CloseStatus=\"failed\"' cadence --do samples-domain wf count -q 'CloseStatus!=\"completed\"' 以上所有命令都可以通过CountWorkflowExecutions API完成 Web UI Support 从release 3.4.0开始，Cadence Web支持查询(打开新窗口)。按“基本/高级”键可切换至“高级”模式，并在搜索框内输入查询。 TLS支持连接Elasticsearch 如果您的elasticsearch部署需要TLS连接到它，您可以将以下内容添加到您的配置模板中。TLS配置是可选的，未提供时默认使用TLS。启用为假 elasticsearch: url: scheme: \"https\" host: \"127.0.0.1:9200\" indices: visibility: cadence-visibility-dev tls: enabled: true caFile: /secrets/cadence/elasticsearch_cert.pem enableHostVerification: true serverName: myServerName certFile: /secrets/cadence/certfile.crt keyFile: /secrets/cadence/keyfile.key sslmode: false 本地运行 增加Docker内存到6GB以上。导航到Docker ->首选项->高级->内存 获取Cadence Docker撰写文件。执行 curl -O https://raw.githubusercontent.com/uber/cadence/master/docker/docker-compose-es.yml Start Cadence Docker (which contains Apache Kafka, Apache Zookeeper, and Elasticsearch) using docker-compose -f docker-compose-es.yml up From the Docker output log, make sure Elasticsearch and Cadence started correctly. If you encounter an insufficient disk space error, try docker system prune -a --volumes 注册一个本地域并开始使用它。cadence --do samples-domain d re 添加键到ElasticSearch，并允许列表搜索属性。cadence --do domain adm cl asa --search_attr_key NewKey --search_attr_type 1 正式环境运行 在Cadence集群中启用该特性。 在ElasticSearch上注册索引模式。按照这个脚本运行两个CURL命令(打开新窗口)。 使用模式创建一个索引模板，根据您的ElasticSearch版本选择v6/v7 按照索引模板创建索引，记住名称 在Kafka上注册主题，并记住名称 根据您的预期吞吐量设置正确的分区数量(稍后可以扩大) 配置Cadence for ElasticSearch + Kafka，就像这个文档(打开新的窗口)基于完整的静态配置，你可以添加一些其他的字段，比如AuthN。同样对卡夫卡。 添加新的搜索属性: Add the key to ElasticSearch cadence --do domain adm cl asa --search_attr_key NewKey --search_attr_type 1 Update the dynamic configuration (opens new window)to allowlist the new attribute 注意:启动一个带有搜索属性但没有高级可见性的工作流会正常成功，但不会被搜索，也不会显示在列表结果中。 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"software/cadence理解.html":{"url":"software/cadence理解.html","title":"cadence理解","keywords":"","body":"Uber Cadenec Cadence is a distributed, scalable, durable, and highly available orchestration engine to execute asynchronous long-running business logic in a scalable and resilient way. 在cadence项目github首页介绍中，如上描述。最重要的有两点。cadence是一个编排引擎,也称为工作流引擎。cadence还是一个分布式的工作流引擎，和适用于异步长事务场景的工作流引擎，当然也支持短事务，但核心的执行引擎是异步的。 编排引擎和工作流引擎其实是一个类似的概念，但是在cadenece的官方站点https://cadenceworkflow.io/中，作者也叫他 Fault-Tolerant Stateful Code Platform，即容错状态代码平台。 在官方站点的use cases中，我们可以看到cadence的一些适用场景，如编排，事件驱动应用，任务批处理，大数据机器学习等。个人认为其实对于cadenece这个产品的定位，作者也不太明确。但是cadence的核心是明确的，就是一个分布式的通用的编排或者工作流引擎。既然是通用的编排引擎，那么它的应用广泛其实也是合理的。 我们如何来理解cadence这个产品呢？ 从抽象的视角来看，cadence是一个分布式的编排或者说工作流引擎。它支持分布式工作流的定义和执行，同时维护工作流的执行状态。 cadence编程模型中有四个主要的角色,在介绍角色之前，需要说明的是，cadence是一个通用的工作流引擎，它的很多术语也借鉴了工作流引擎中的术语。如workflow、activity、Worker、Decider等。 Activity Worker: 活动执行者，在分布式事务中叫做分支事务执行者。主要用来接收cadence传递过来的活动任务(Activity Task),并执行本地事务。 workflow worker: 工作流执行者，也叫Decider决策者。在分布式事务场景中，这个角色相当于全局事务流程执行者。 它根据cadence发送过来的这些决策任务(Decision Task)驱动全局事务流程的执行。 workflow starter: 负责启动整个工作流 cadence：负责整个工作流的编排和协调。 由于cadence场景很多。根据场景的不通。三种角色也可以被称为其他的名称 Cadence 微服务架构 Matching Service 匹配服务，任务派遣Dispatching。他接收来自HistortService的活动或者是决策任务，存储在Task Storage中。他将任务派遣给这些Activity worker或者workflow worker History Service,接收starter的启动工作流指令，然后调度决策或者是活动任务，下发给匹配服务去做任务派遣。他也接收来自Activity或者是workflow这些worker的执行响应。根据响应的结果在调度新的决策或者是活动任务。History service将工作流执行的任务步骤记录在工作流存储当做。也将工作流执行过程中发生的事件，记录在事件存储中。也将工作流的状态执行信息保存在Visbitil存储中。 Front End 类似于BFF服务。是一个门面服务。主要用来屏蔽内部的这些微服务的复杂性。外围的客户端服务只能通过Front End服务与Cadence内部服务交互。 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "},"software/cadence-golang客户端.html":{"url":"software/cadence-golang客户端.html","title":"cadence-golang客户端","keywords":"","body":"介绍 概览 Cadence要求工作流代码的决定论。它支持多线程代码的确定性执行，以及像select这样的由Go设计而非确定性的结构。Cadence解决方案以接口的形式提供相应的结构，这些接口具有类似的功能，但支持确定性执行。 例如，工作流代码必须使用工作流，而不是原生的Go通道。通道接口。而不是选择工作流。必须使用选择器接口。 有关更多信息，请参见创建工作流。 链接 GitHub project: https://github.com/uber-go/cadence-client Samples: https://github.com/uber-common/cadence-samples GoDoc documentation: https://godoc.org/go.uber.org/cadence Worker service 工作者或工作者服务是托管工作流和活动实现的服务。worker向Cadence服务轮询任务，执行任务，并将任务执行结果反馈给Cadence服务。工人服务由Cadence客户开发、部署和运营。 您可以在新的或现有的服务中运行一个Cadence worker。使用框架api来启动Cadence worker，并链接所有需要服务执行的活动和工作流实现。 package main import ( \"github.com/uber-go/tally\" \"go.uber.org/cadence/.gen/go/cadence/workflowserviceclient\" \"go.uber.org/cadence/worker\" \"go.uber.org/yarpc\" \"go.uber.org/yarpc/transport/tchannel\" \"go.uber.org/zap\" \"go.uber.org/zap/zapcore\" \"strings\" ) var HostPort = \"10.0.0.35:7933\" var Domain = \"SimpleDomain\" var TaskListName = \"SimpleWorker\" var ClientName = \"SimpleWorker\" var CadenceService = \"cadence-frontend\" func main(){ startWorker(buildLogger(),buildCadenceClient()) select { } } func buildLogger()*zap.Logger{ config:=zap.NewDevelopmentConfig() config.Level.SetLevel(zapcore.InfoLevel) var err error logger,err:= config.Build() if err!=nil{ panic(\"Failed to setup logger\") } return logger } func buildCadenceClient()workflowserviceclient.Interface{ ch,err:=tchannel.NewChannelTransport(tchannel.ServiceName(ClientName)) if err != nil { panic(\"Failed to setup tchannel\") } // Dispatcher封装了一个YARPC应用程序。它充当入口点，以传输和编码无关的方式发送和接收YARPC请求。 // Outbounds 为远程服务提供访问。定义请求如何从此服务发送到远程服务 dispatcher :=yarpc.NewDispatcher(yarpc.Config{ Name: strings.ToLower(ClientName), Outbounds: yarpc.Outbounds{ CadenceService: {Unary: ch.NewSingleOutbound(HostPort)}, }, }) if err := dispatcher.Start(); err != nil { panic(\"Failed to start dispatcher\") } return workflowserviceclient.New(dispatcher.ClientConfig(CadenceService)) } func startWorker(logger *zap.Logger,service workflowserviceclient.Interface){ // TaskListName标识一组客户端工作流、活动和工作者。 // 它可以是您的组名、客户机名或应用程序名。 workerOptions :=worker.Options{ Logger: logger, MetricsScope: tally.NewTestScope(TaskListName, map[string]string{}), } worker1 := worker.New( service, Domain, TaskListName, workerOptions, ) err :=worker1.Start() if err !=nil{ panic(\"Failed to start worker\") } logger.Info(\"Started Worker.\", zap.String(\"worker\", TaskListName)) } Creating workflows 工作流是协调逻辑的实现。Cadence编程框架(又名客户端库)允许您将工作流协调逻辑编写为使用标准Go数据建模的简单过程代码。客户端库负责worker服务和Cadence服务之间的通信，并确保事件之间的状态持久性，即使在worker失败的情况下。此外，任何特定的执行都不绑定到特定的工作机器。协调逻辑的不同步骤最终可能在不同的工作人员实例上执行，框架确保在执行该步骤的工作人员上重新创建必要的状态。 然而，为了方便这种操作模型，Cadence编程框架和托管服务都对协调逻辑的实现施加了一些要求和限制。下面的实现部分将详细描述这些需求和限制。 概述 下面的示例代码显示了执行一个活动的工作流的简单实现。工作流还将它在初始化过程中接收到的唯一参数作为活动的参数传递。 声名 在Cadence编程模型中，用一个函数实现了工作流。函数声明指定了工作流接受的参数以及它可能返回的任何值。 func SimpleWorkflow(ctx workflow.Context, value string) error 函数的第一个参数是ctx workflow.Context。这是所有工作流函数所需的参数，Cadence客户端库使用它来传递执行上下文。实际上，所有可从工作流函数调用的客户端库函数都需要这个ctx参数。这个context参数与标准context是同一个概念。Go提供的上下文。工作流之间的唯一区别。上下文和语境。上下文是工作流中的Done()函数。上下文返回工作流。频道改为标准的go chan。 第二个参数string是一个自定义工作流参数，可用于在开始时将数据传递到工作流中。工作流可以有一个或多个这样的参数。工作流函数的所有参数必须是可序列化的，这本质上意味着参数不能是通道、函数、可变参数或不安全的指针。 因为它只声明error作为返回值，这意味着工作流不返回值。错误返回值用于指示在执行过程中遇到了错误，应该终止工作流。 执行 为了支持工作流实现的同步和顺序编程模型，对于工作流实现必须如何行为以保证正确性有一定的限制和要求。要求是 执行必须是确定性的 执行必须是幂等的 考虑这些需求的一个简单方法是工作流代码如下: 工作流代码只能读取和操作本地状态或从Cadence客户端库函数返回值接收的状态 工作流代码不应该影响外部系统中的更改，除非通过调用活动。 工作流代码应该只通过Cadence客户端库提供的函数与时间交互(即Workflow . now ()， Workflow . sleep())。 工作流代码不应该直接创建和与goroutines交互，它应该使用Cadence客户端库提供的函数 (workflow.Go() instead of go, workflow.Channel instead of chan, workflow.Selector instead of select). 工作流代码应该通过Cadence客户端库(即Workflow . getlogger())提供的记录器进行所有日志记录。 工作流代码不应该在使用range的地图上迭代，因为地图迭代的顺序是随机的。 现在我们已经奠定了基本规则，我们可以看一下用于编写Cadence工作流的一些特殊函数和类型，以及如何实现一些常见模式。 特殊Cadence客户端库函数和类型： Cadence客户端库提供了许多函数和类型作为一些原生Go函数和类型的替代。使用这些替换函数/类型是必要的，以确保工作流代码执行在执行上下文中是确定的和可重复的。 协程相关的构造: workflow.Go : 这是go语句的替换。 workflow.Channel : 这是对原生chan类型的替换。Cadence同时支持缓冲和非缓冲通道 workflow.Selector: 这是对select语句的替换。 时间相关函数: workflow.Now()： time.now的替代品。 workflow.Sleep() time.sleep()的替代品。 失败 要将工作流标记为失败，只需要工作流函数通过err返回值返回一个错误即可 注册 对于一些能够调用工作流类型的客户机代码，工作进程需要知道它能够访问的所有实现。工作流通过以下调用注册: workflow.Register(SimpleWorkflow) `这个调用实际上在工作进程内部创建了一个完全限定函数名和实现之间的内存映射。从init()函数调用这个注册方法是安全的。如果工作者接收到它不知道的工作流类型的任务，它将使该任务失败。但是，任务失败不会导致整个工作流失败。 活动概览 活动是业务逻辑中特定任务的实现。 活动被实现为函数。数据可以通过函数参数直接传递给活动。参数可以是基本类型或结构，唯一的要求是参数必须是可序列化的。虽然不是必需的，但是我们建议活动函数的第一个参数是context类型的。上下文，以允许活动与其他框架方法交互。函数必须返回一个错误值，也可以有选择地返回结果值。结果值可以是基本类型，也可以是结构体，唯一的要求是它是可序列化的。 通过调用参数传递给活动或通过结果值返回的值记录在执行历史中。在工作流逻辑需要处理的每个事件中，整个执行历史都从Cadence服务转移到工作流工作者。因此，较大的执行历史可能会对工作流的性能产生负面影响。因此，要注意通过活动调用参数或返回值传输的数据量。否则，活动实现上不存在额外的限制。 概览 下面的示例演示了一个简单的活动，该活动接受一个字符串参数，向其添加一个单词，然后返回结果。 package simple import ( \"context\" \"go.uber.org/cadence/activity\" \"go.uber.org/zap\" ) func init() { activity.Register(SimpleActivity) } // SimpleActivity is a sample Cadence activity function that takes one parameter and // returns a string containing the parameter value. func SimpleActivity(ctx context.Context, value string) (string, error) { activity.GetLogger(ctx).Info(\"SimpleActivity called.\", zap.String(\"Value\", value)) return \"Processed: \" + value, nil } 让我们看看这个活动的每个组件。 在Cadence编程模型中，活动是用函数实现的。函数声明指定了活动接受的参数以及它可能返回的值。一个活动函数可以采取零个或多个活动特定参数，并可以返回一个或两个值。它必须至少返回一个错误值。活动函数可以接受任何可序列化类型作为参数并返回结果。 func SimpleActivity(ctx context.Context, value string) (string, error) 函数的第一个参数是context.Context。这是一个可选参数，可以省略。该参数是标准的Go上下文。第二个字符串参数是特定于活动的自定义参数，可用于在开始时将数据传递到活动中。一个活动可以有一个或多个这样的参数。活动函数的所有参数必须是可序列化的，这本质上意味着参数不能是通道、函数、可变参数或不安全的指针。该活动声明了两个返回值:string和error。的返回值用于返回结果. 您可以按照编写任何其他Go服务代码的相同方式编写活动实现代码。此外，您可以使用常用的记录器和度量控制器，以及标准的Go并发结构 心跳 对于长时间运行的活动，Cadence为活动代码提供了一个API，向Cadence管理的服务报告活动和进度。 progress := 0 for hasWork { // Send heartbeat message to the server. cadence.RecordActivityHeartbeat(ctx, progress) // Do some work. ... progress++ } When an activity times out due to a missed heartbeat, the last value of the details (progress in the above sample) is returned from the cadence.ExecuteActivity function as the details field of TimeoutError with TimeoutType_HEARTBEAT. Cadence Go Client 0.17.0版本中新的自动心跳选项(打开新窗口):如果你不需要报告进度，但仍然想通过长时间运行的活动的心跳报告工作人员的活跃度，有一个新的自动心跳选项，你可以在注册活动时启用。当启用此选项时，Cadence库将在后台为你做心跳。 RegisterActivityOptions struct { ... // Automatically send heartbeats for this activity at an interval that is less than the HeartbeatTimeout. // This option has no effect if the activity is executed with a HeartbeatTimeout of 0. // Default: false EnableAutoHeartbeat bool } 你也可以从外部源检测一个活动: // Instantiate a Cadence service client. cadence.Client client = cadence.NewClient(...) // Record heartbeat. err := client.RecordActivityHeartbeat(taskToken, details) taskToken:在活动内部检索到的ActivityInfo结构体的二进制taskToken字段的值。 details:包含进度信息的可序列化负载 当一个活动被取消，或者它的工作流执行完成或失败时，传递给它的函数的上下文被取消，这将其通道的关闭状态设置为Done。活动可以使用它来执行任何必要的清理和中止执行。取消只交付给调用RecordActivityHeartbeat的活动。 注册 为了使该活动对托管它的工作进程可见，该活动必须通过调用activity. register进行注册。 func init() { activity.Register(SimpleActivity) } 这个调用在工作进程内部的完全限定函数名和实现之间创建了一个内存映射。如果一个worker接收到一个请求来启动一个它不知道的活动类型的活动执行，它将使该请求失败。 错误活动 要将一个活动标记为失败，活动函数必须通过错误返回值返回一个错误。 Copyright © Du Yong all right reserved，powered by Gitbook该文件修订时间： 2022-06-09 10:12:33 "}}